{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOUwYPRyiG2XzlZe1Hye4+a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SongXihao-Alan/Tic-Tac-Toe/blob/main/tic_tac_toe_game_with_random_move.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **调用库**"
      ],
      "metadata": {
        "id": "SeRoztGIh3ge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install -y xvfb ffmpeg freeglut3-dev\n",
        "!pip install imageio>=2.5,<3.0 --upgrade\n",
        "!pip install imageio imageio-ffmpeg\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install tf-agents\n",
        "!pip install tf-agents[reverb]\n",
        "!pip install pyglet\n",
        "import cv2\n",
        "import gym\n",
        "from gym import spaces\n",
        "import base64\n",
        "import imageio\n",
        "import unittest\n",
        "import IPython\n",
        "import matplotlib\n",
        "import PIL.Image\n",
        "import pyvirtualdisplay\n",
        "import reverb\n",
        "import numpy as np  # 这是python中常用的指令，调用库numpy并在以后重命名为np\n",
        "import matplotlib.pyplot as plt # 这是python中常用的指令，调用库matplotlib重的pyplot模块并在以后重命名为plt\n",
        "import tensorflow as tf # 调用tensorflow库\n",
        "import imageio\n",
        "\n",
        "from IPython.display import Video\n",
        "from tf_agents import utils\n",
        "from tf_agents.agents.dqn import dqn_agent\n",
        "from tf_agents.drivers import py_driver\n",
        "from tf_agents.drivers import dynamic_step_driver\n",
        "from tf_agents.environments import suite_gym\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.environments import py_environment\n",
        "from tf_agents.environments import utils\n",
        "from tf_agents.eval import metric_utils\n",
        "from tf_agents.metrics import tf_metrics\n",
        "from tf_agents.eval.metric_utils import log_metrics\n",
        "from tf_agents.networks import sequential\n",
        "from tf_agents.networks import network\n",
        "from tf_agents.networks import q_network\n",
        "from tf_agents.policies import py_tf_eager_policy\n",
        "from tf_agents.policies import random_tf_policy\n",
        "from tf_agents.replay_buffers import reverb_replay_buffer\n",
        "from tf_agents.replay_buffers import reverb_utils\n",
        "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
        "from tf_agents.trajectories import trajectory\n",
        "from tf_agents.trajectories import time_step as ts\n",
        "from tf_agents.specs import tensor_spec\n",
        "from tf_agents.specs import array_spec\n",
        "from tf_agents.utils import common\n",
        "from __future__ import absolute_import, division, print_function\n",
        "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1r6K72k9hYmx",
        "outputId": "472a3174-3835-49c1-c4fd-ab9ba3647b70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com] [1 In\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com] [Conn\r                                                                               \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [637 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,305 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,247 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,599 kB]\n",
            "Get:15 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,153 kB]\n",
            "Get:16 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [39.8 kB]\n",
            "Fetched 7,258 kB in 2s (3,914 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "The following additional packages will be installed:\n",
            "  freeglut3 libegl-dev libfontenc1 libgl-dev libgl1-mesa-dev libgles-dev\n",
            "  libgles1 libglu1-mesa libglu1-mesa-dev libglvnd-core-dev libglvnd-dev\n",
            "  libglx-dev libice-dev libopengl-dev libsm-dev libxfont2 libxkbfile1\n",
            "  libxt-dev x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
            "  xserver-common\n",
            "Suggested packages:\n",
            "  libice-doc libsm-doc libxt-doc\n",
            "The following NEW packages will be installed:\n",
            "  freeglut3 freeglut3-dev libegl-dev libfontenc1 libgl-dev libgl1-mesa-dev\n",
            "  libgles-dev libgles1 libglu1-mesa libglu1-mesa-dev libglvnd-core-dev\n",
            "  libglvnd-dev libglx-dev libice-dev libopengl-dev libsm-dev libxfont2\n",
            "  libxkbfile1 libxt-dev x11-xkb-utils xfonts-base xfonts-encodings\n",
            "  xfonts-utils xserver-common xvfb\n",
            "0 upgraded, 25 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 9,074 kB of archives.\n",
            "After this operation, 18.7 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 freeglut3 amd64 2.8.1-6 [74.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglx-dev amd64 1.4.0-1 [14.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgl-dev amd64 1.4.0-1 [101 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-core-dev amd64 1.4.0-1 [12.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libegl-dev amd64 1.4.0-1 [18.0 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles1 amd64 1.4.0-1 [11.5 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles-dev amd64 1.4.0-1 [49.4 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libopengl-dev amd64 1.4.0-1 [3,400 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-dev amd64 1.4.0-1 [3,162 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgl1-mesa-dev amd64 23.0.4-0ubuntu1~22.04.1 [6,510 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa amd64 9.0.2-1 [145 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa-dev amd64 9.0.2-1 [231 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libice-dev amd64 2:1.0.10-1build2 [51.4 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsm-dev amd64 2:1.2.3-1build2 [18.1 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/universe amd64 freeglut3-dev amd64 2.8.1-6 [126 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.5 [28.2 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.5 [863 kB]\n",
            "Fetched 9,074 kB in 4s (2,592 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 25.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package freeglut3:amd64.\n",
            "(Reading database ... 121666 files and directories currently installed.)\n",
            "Preparing to unpack .../00-freeglut3_2.8.1-6_amd64.deb ...\n",
            "Unpacking freeglut3:amd64 (2.8.1-6) ...\n",
            "Selecting previously unselected package libglx-dev:amd64.\n",
            "Preparing to unpack .../01-libglx-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglx-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl-dev:amd64.\n",
            "Preparing to unpack .../02-libgl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libglvnd-core-dev:amd64.\n",
            "Preparing to unpack .../03-libglvnd-core-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libegl-dev:amd64.\n",
            "Preparing to unpack .../04-libegl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libegl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgles1:amd64.\n",
            "Preparing to unpack .../05-libgles1_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgles1:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgles-dev:amd64.\n",
            "Preparing to unpack .../06-libgles-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgles-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libopengl-dev:amd64.\n",
            "Preparing to unpack .../07-libopengl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libopengl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libglvnd-dev:amd64.\n",
            "Preparing to unpack .../08-libglvnd-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglvnd-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl1-mesa-dev:amd64.\n",
            "Preparing to unpack .../09-libgl1-mesa-dev_23.0.4-0ubuntu1~22.04.1_amd64.deb ...\n",
            "Unpacking libgl1-mesa-dev:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
            "Selecting previously unselected package libglu1-mesa:amd64.\n",
            "Preparing to unpack .../10-libglu1-mesa_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package libglu1-mesa-dev:amd64.\n",
            "Preparing to unpack .../11-libglu1-mesa-dev_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa-dev:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package libice-dev:amd64.\n",
            "Preparing to unpack .../12-libice-dev_2%3a1.0.10-1build2_amd64.deb ...\n",
            "Unpacking libice-dev:amd64 (2:1.0.10-1build2) ...\n",
            "Selecting previously unselected package libsm-dev:amd64.\n",
            "Preparing to unpack .../13-libsm-dev_2%3a1.2.3-1build2_amd64.deb ...\n",
            "Unpacking libsm-dev:amd64 (2:1.2.3-1build2) ...\n",
            "Selecting previously unselected package libxt-dev:amd64.\n",
            "Preparing to unpack .../14-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n",
            "Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Selecting previously unselected package freeglut3-dev:amd64.\n",
            "Preparing to unpack .../15-freeglut3-dev_2.8.1-6_amd64.deb ...\n",
            "Unpacking freeglut3-dev:amd64 (2.8.1-6) ...\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../16-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../17-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../18-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../19-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../20-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../21-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../22-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../23-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.5_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.5) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../24-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.5_amd64.deb ...\n",
            "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.5) ...\n",
            "Setting up freeglut3:amd64 (2.8.1-6) ...\n",
            "Setting up libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libice-dev:amd64 (2:1.0.10-1build2) ...\n",
            "Setting up libsm-dev:amd64 (2:1.2.3-1build2) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Setting up libgles1:amd64 (1.4.0-1) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up libglx-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libopengl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up libgl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libegl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up libglu1-mesa-dev:amd64 (9.0.2-1) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.5) ...\n",
            "Setting up libgles-dev:amd64 (1.4.0-1) ...\n",
            "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.5) ...\n",
            "Setting up libglvnd-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libgl1-mesa-dev:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
            "Setting up freeglut3-dev:amd64 (2.8.1-6) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "/bin/bash: line 1: 3.0: No such file or directory\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.10/dist-packages (0.4.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio) (1.23.5)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg) (67.7.2)\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyvirtualdisplay\n",
            "Successfully installed pyvirtualdisplay-3.0\n",
            "Collecting tf-agents\n",
            "  Downloading tf_agents-0.19.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from tf-agents) (1.4.0)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents) (2.2.1)\n",
            "Requirement already satisfied: gin-config>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents) (0.5.0)\n",
            "Collecting gym<=0.23.0,>=0.17.0 (from tf-agents)\n",
            "  Downloading gym-0.23.0.tar.gz (624 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m624.4/624.4 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents) (1.23.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from tf-agents) (9.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents) (1.16.0)\n",
            "Requirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents) (3.20.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from tf-agents) (1.14.1)\n",
            "Requirement already satisfied: typing-extensions==4.5.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents) (4.5.0)\n",
            "Collecting pygame==2.1.3 (from tf-agents)\n",
            "  Downloading pygame-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-probability~=0.23.0 (from tf-agents)\n",
            "  Downloading tensorflow_probability-0.23.0-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym<=0.23.0,>=0.17.0->tf-agents) (0.0.8)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability~=0.23.0->tf-agents) (4.4.2)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability~=0.23.0->tf-agents) (0.5.4)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability~=0.23.0->tf-agents) (0.1.8)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.23.0-py3-none-any.whl size=697631 sha256=d556f85f7984e8b79c0f808992b29ef47623457f18cc2be77ce83f29e1d7c99a\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/6f/b4/3991d4fae11d0ecb0754c11cc1b4e7745012850da4efaaf0b1\n",
            "Successfully built gym\n",
            "Installing collected packages: tensorflow-probability, pygame, gym, tf-agents\n",
            "  Attempting uninstall: tensorflow-probability\n",
            "    Found existing installation: tensorflow-probability 0.22.0\n",
            "    Uninstalling tensorflow-probability-0.22.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.22.0\n",
            "  Attempting uninstall: pygame\n",
            "    Found existing installation: pygame 2.5.2\n",
            "    Uninstalling pygame-2.5.2:\n",
            "      Successfully uninstalled pygame-2.5.2\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "Successfully installed gym-0.23.0 pygame-2.1.3 tensorflow-probability-0.23.0 tf-agents-0.19.0\n",
            "Requirement already satisfied: tf-agents[reverb] in /usr/local/lib/python3.10/dist-packages (0.19.0)\n",
            "Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.4.0)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (2.2.1)\n",
            "Requirement already satisfied: gin-config>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.5.0)\n",
            "Requirement already satisfied: gym<=0.23.0,>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.23.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (9.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.16.0)\n",
            "Requirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (3.20.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.14.1)\n",
            "Requirement already satisfied: typing-extensions==4.5.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (4.5.0)\n",
            "Requirement already satisfied: pygame==2.1.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (2.1.3)\n",
            "Requirement already satisfied: tensorflow-probability~=0.23.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.23.0)\n",
            "Collecting rlds (from tf-agents[reverb])\n",
            "  Downloading rlds-0.1.8-py3-none-manylinux2010_x86_64.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m881.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dm-reverb~=0.14.0 (from tf-agents[reverb])\n",
            "  Downloading dm_reverb-0.14.0-cp310-cp310-manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow~=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (2.15.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from dm-reverb~=0.14.0->tf-agents[reverb]) (0.1.8)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.10/dist-packages (from dm-reverb~=0.14.0->tf-agents[reverb]) (1.5.2)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (0.0.8)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (23.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (67.7.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (2.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (2.15.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability~=0.23.0->tf-agents[reverb]) (4.4.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.15.0->tf-agents[reverb]) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (3.0.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from portpicker->dm-reverb~=0.14.0->tf-agents[reverb]) (5.9.5)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (3.2.2)\n",
            "Installing collected packages: rlds, dm-reverb\n",
            "Successfully installed dm-reverb-0.14.0 rlds-0.1.8\n",
            "Collecting pyglet\n",
            "  Downloading pyglet-2.0.10-py3-none-any.whl (858 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m858.3/858.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyglet\n",
            "Successfully installed pyglet-2.0.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Environment**"
      ],
      "metadata": {
        "id": "Zno4UozwEEgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TicTacToeEnv(gym.Env):\n",
        "    metadata = {'render.modes': ['human']}\n",
        "    #define a initial state, empty board\n",
        "    def __init__(self):\n",
        "        super(TicTacToeEnv, self).__init__()\n",
        "        self.board_size = 9 # The length of the board\n",
        "        self.win_length = 4 # The length of the line needed to win\n",
        "        self.action_space = spaces.Discrete(self.board_size**2)\n",
        "        self.observation_space = spaces.Box(low=-1, high=1, shape=(self.board_size, self.board_size), dtype=np.int8)# Define Observation space with 9x9 grid, range of element is -1, 0, 1.\n",
        "\n",
        "        # Define state_size and action_size\n",
        "        self.state_size = self.board_size * self.board_size  # Total number of cells in the board\n",
        "        self.action_size = self.action_space.n  # Total number of possible actions\n",
        "\n",
        "        self.state = None # Attribute of the enviornment class to None means the enivornment is an unintialized state\n",
        "        self.current_player = 1 # First player's turn\n",
        "        self.reset()#start a new game by resetting the environment to a default state\n",
        "\n",
        "    def current_player(self):\n",
        "        return self._current_player\n",
        "\n",
        "    #start a new game by resetting the environment to a initial state, empty board\n",
        "    def reset(self):\n",
        "        self.state = np.zeros((self.board_size, self.board_size), dtype=np.int8) # self.state is assigned a new Numpy 9x9 array of zeros.\n",
        "        self.current_player = 1 # First player's turn for whatever the new game starts\n",
        "        return self.state  #returns the initial state of the environment, the empty game board\n",
        "\n",
        "\n",
        "    #Defines how the environment reacts to an action taken by an agent. When agent's action is taken, it suppose to update the enviornment's state.\n",
        "    def step(self, action):\n",
        "        row, col = divmod(action, self.board_size)\n",
        "\n",
        "    # Random move adjustment\n",
        "        if np.random.rand() < 0.5:\n",
        "            neighbors = self.get_neighbors(row, col)\n",
        "            if neighbors:\n",
        "                row, col = neighbors[np.random.choice(len(neighbors))]\n",
        "    # If the move is invalid, switch players and return\n",
        "        if not self.is_valid_move(row, col):\n",
        "            self.current_player *= -1\n",
        "            return self.state, 0, False, {\"message\": \"Move forfeited: Jump to the opponent's turn\"}\n",
        "\n",
        "    # Apply the move for the current player\n",
        "        self.state[row, col] = self.current_player\n",
        "\n",
        "    # Check for a winner\n",
        "        winner = self.check_winner()\n",
        "        done = winner is not None or not np.any(self.state == 0)\n",
        "        reward = self.calculate_reward(winner)\n",
        "    # Switch players for the next turn\n",
        "        self.current_player *= -1\n",
        "\n",
        "        return self.state, reward, done, {}\n",
        "\n",
        "    def get_neighbors(self, row, col):\n",
        "        neighbors = []\n",
        "        for dr in [-1, 0, 1]:\n",
        "            for dc in [-1, 0, 1]:\n",
        "                if dr == 0 and dc == 0:\n",
        "                    continue  # Skip the original cell\n",
        "                new_row, new_col = row + dr, col + dc\n",
        "                if self.is_on_board(new_row, new_col):\n",
        "                    neighbors.append((new_row, new_col))\n",
        "        return neighbors\n",
        "\n",
        "\n",
        "    def is_on_board(self, row, col):\n",
        "        return 0 <= row < self.board_size and 0 <= col < self.board_size #returns True if both the row and column indices are within the range of 0 to self.board_size - 1.\n",
        "\n",
        "    def is_valid_move(self, row, col): #determines if a move to a given cell is valid.\n",
        "        return self.is_on_board(row, col) and self.state[row, col] == 0\n",
        "\n",
        "    # visually rendering the current state of the Tic-Tac-Toe board in the console.\n",
        "    def render(self, mode='human', close=False):\n",
        "        if mode == 'rgb_array':\n",
        "            return self.render_rgb_array()\n",
        "        else:\n",
        "            # Correctly indented code block for 'human' mode rendering\n",
        "            h_line = \"+---\" * self.board_size + \"+\"\n",
        "            print(h_line)\n",
        "            for row in self.state:\n",
        "                row_str = \"|\" + \"|\".join(' X ' if cell == 1 else ' O ' if cell == -1 else '   ' for cell in row) + \"|\"\n",
        "                print(row_str)\n",
        "                print(h_line)\n",
        "            if close:\n",
        "                self.close()\n",
        "\n",
        "    def render_rgb_array(self):\n",
        "        # Create an image of the board state\n",
        "        data = np.zeros((self.board_size, self.board_size, 3), dtype=np.uint8)\n",
        "        for i in range(self.board_size):\n",
        "            for j in range(self.board_size):\n",
        "                if self.state[i, j] == 1:\n",
        "                    data[i, j] = [255, 0, 0]  # Red for player 1\n",
        "                elif self.state[i, j] == -1:\n",
        "                    data[i, j] = [0, 0, 255]  # Blue for player 2\n",
        "\n",
        "        # Convert array to image and resize for better visibility\n",
        "        img = cv2.resize(data, (300, 300), interpolation=cv2.INTER_NEAREST)\n",
        "        return img\n",
        "\n",
        "    def close(self):\n",
        "        if self.some_resource:  # Check if a certain resource is initialized\n",
        "            self.some_resource.close()  # Properly close or release the resource\n",
        "        if self.graphical_interface:  # Check if a graphical interface is used\n",
        "            self.graphical_interface.destroy()  # Close or destroy the interface\n",
        "\n",
        "        if self.network_connection:  # Check if there's an open network connection\n",
        "            self.network_connection.close()  # Close the network connection\n",
        "        print(\"Tic-Tac-Toe environment resources have been released.\")\n",
        "        print(\"Closing Tic-Tac-Toe environment.\")\n",
        "\n",
        "    # Win condition\n",
        "    def check_winner(self):\n",
        "    # Check rows, columns, and diagonals for a win\n",
        "        for row in range(self.board_size):\n",
        "            for col in range(self.board_size):\n",
        "                if self.state[row, col] != 0:  # For each cell that is not empty\n",
        "                # Checking all eight directions\n",
        "                    if (self.check_line(row, col, 1, 0) or  # Horizontal (right)\n",
        "                        self.check_line(row, col, 0, 1) or  # Vertical (down)\n",
        "                        self.check_line(row, col, 1, 1) or  # Diagonal (down-right, ↘)\n",
        "                        self.check_line(row, col, -1, 1) or  # Diagonal (up-right, ↗)\n",
        "                        self.check_line(row, col, -1, -1) or  # Diagonal (up-left, ↖)\n",
        "                        self.check_line(row, col, 1, -1) or  # Diagonal (down-left, ↙)\n",
        "                        self.check_line(row, col, -1, 0) or  # Vertical (up)\n",
        "                        self.check_line(row, col, 0, -1)):  # Horizontal (left)\n",
        "                        return self.state[row, col]\n",
        "        return None\n",
        "\n",
        "\n",
        "    def check_line(self, start_row, start_col, d_row, d_col): #start_row and start_col specify the starting cell, and d_row and d_col specify the direction to check in.\n",
        "        \"\"\"Check a line of pieces in the board.\"\"\"\n",
        "        end_row = start_row + (self.win_length - 1) * d_row\n",
        "        end_col = start_col + (self.win_length - 1) * d_col\n",
        "        if 0 <= end_row < self.board_size and 0 <= end_col < self.board_size:\n",
        "            for i in range(self.win_length): #If any cell in this line does not match the player number in the starting cell, it returns False\n",
        "                if self.state[start_row + i * d_row, start_col + i * d_col] != self.state[start_row, start_col]:\n",
        "                    return False\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def calculate_reward(self, winner):\n",
        "        if winner is None:\n",
        "            return 0  # No winner yet, or it's a draw\n",
        "        elif winner == 1:\n",
        "            return 1  # Player 1 wins, reward is 1\n",
        "        else:\n",
        "            return -1  # Player 2 wins, reward is -1\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l4SFYPOzngzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = TicTacToeEnv()\n",
        "initial_state = env.reset() #Resetting the Environment\n",
        "print(\"Initial State:\\n\", initial_state)\n",
        "# Initialize the environment and agent\n",
        "env.render() #Rendering the Initial State\n",
        "#action = env.action_space.sample()\n",
        "action = 77 # Randomly sample an action\n",
        "state, reward, done, info = env.step(action)\n",
        "env.render()\n",
        "\n",
        "print(\"New State:\\n\", state)\n",
        "print(\"Reward:\", reward)\n",
        "print(\"Game Over:\", done)\n",
        "print(\"Additional Info:\", info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOFXybUPkeYs",
        "outputId": "3fd9755a-e7ea-41a9-8539-35e4890ef6cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial State:\n",
            " [[0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]]\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   | X |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "New State:\n",
            " [[0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0]]\n",
            "Reward: 0\n",
            "Game Over: False\n",
            "Additional Info: {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **test Enviornment**"
      ],
      "metadata": {
        "id": "khJNSS6Thw6G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the Win Condition"
      ],
      "metadata": {
        "id": "MLTWtjCmFECJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the environment\n",
        "env = TicTacToeEnv()\n",
        "print(\"Current Player before the move:\", \"Player 1\" if env.current_player == 1 else \"Player 2\")\n",
        "# Define a board state where player 1 is one move away from winning horizontally\n",
        "env.state = np.array([\n",
        "    [ 1,  1,  1,  0,  0,  0,  0,  0,  0],\n",
        "    [ 0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
        "    [ 0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
        "    [ 0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
        "    [ 0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
        "    [ 0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
        "    [ 0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
        "    [ 0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
        "    [ 0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
        "])\n",
        "\n",
        "# Print the current board state before the move\n",
        "print(\"Board State Before the Move:\")\n",
        "env.render()\n",
        "\n",
        "# Winning action for player 1 is to place a marker in the empty spot (row 0, column 3)\n",
        "winning_action_for_player_1 = 0 * env.board_size + 3  # Convert 2D coordinate to 1D action index\n",
        "\n",
        "# Perform the action\n",
        "new_state, reward, done, info = env.step(winning_action_for_player_1)\n",
        "\n",
        "# Print the board state after the move\n",
        "print(\"Board State After the Move:\")\n",
        "env.render()\n",
        "\n",
        "# Check the result\n",
        "winner = env.check_winner()\n",
        "print(\"Winner:\", \"Player 1\" if winner == 1 else \"Player 2\" if winner == -1 else \"No winner\")\n",
        "print(\"Reward:\", reward)\n",
        "# Assert the result (this will raise an error if the assertion is false)\n",
        "assert winner == 1, \"Player 1 should have won\"\n",
        "print(\"Current Player before the move:\", \"Player 1\" if env.current_player == 1 else \"Player 2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjcNquIzFE9g",
        "outputId": "df4ac865-78a6-49f7-d6e5-48f805c892e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Player before the move: Player 1\n",
            "Board State Before the Move:\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "| X | X | X |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "Board State After the Move:\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "| X | X | X | X |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "Winner: Player 1\n",
            "Reward: 1\n",
            "Current Player before the move: Player 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the environment\n",
        "env.reset()\n",
        "env = TicTacToeEnv()\n",
        "env.current_player = -1\n",
        "print(\"Current Player before the move:\", \"Player 1\" if env.current_player == 1 else \"Player 2\")\n",
        "# Define a board state where player 1 is one move away from winning horizontally\n",
        "env.state = np.array([\n",
        "    [ -1,  -1,  -1,  0,  0,  0,  0,  0,  0],\n",
        "    [ 0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
        "    [ 0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
        "    [ 0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
        "    [ 0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
        "    [ 0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
        "    [ 0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
        "    [ 0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
        "    [ 0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
        "])\n",
        "\n",
        "\n",
        "# Print the board state before the winning move\n",
        "print(\"Board State Before the Move (Player 2):\")\n",
        "env.render()\n",
        "\n",
        "# Print the current board state before the move\n",
        "print(\"Board State Before the Move:\")\n",
        "env.render()\n",
        "\n",
        "# Winning action for player 2 is to place a marker in the empty spot (row 0, column 3)\n",
        "winning_action_for_player_2 = 0 * env.board_size + 3  # Convert 2D coordinate to 1D action index\n",
        "\n",
        "print(winning_action_for_player_2)\n",
        "\n",
        "# Perform the action for player 2\n",
        "new_state, reward, done, info = env.step(winning_action_for_player_2)\n",
        "\n",
        "#print(new_state)\n",
        "# Print the board state after the winning move\n",
        "print(\"Board State After the Move (Player 2):\")\n",
        "env.render()\n",
        "\n",
        "# Check and print the winner\n",
        "winner = env.check_winner()\n",
        "print(\"Winner:\", \"Player 1\" if winner == 1 else \"Player 2\" if winner == -1 else \"No winner\")\n",
        "print(\"reward\", reward)\n",
        "# Assert the result\n",
        "assert winner == -1, \"Player 2 should have won\"\n",
        "\n",
        "print(\"Current Player before the move:\", \"Player 1\" if env.current_player == 1 else \"Player 2\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQjWwbWtGrIa",
        "outputId": "160461ef-b380-41a4-b745-e198afed40ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Player before the move: Player 2\n",
            "Board State Before the Move (Player 2):\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "| O | O | O |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "Board State Before the Move:\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "| O | O | O |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "3\n",
            "Board State After the Move (Player 2):\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "| O | O | O | O |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "|   |   |   |   |   |   |   |   |   |\n",
            "+---+---+---+---+---+---+---+---+---+\n",
            "Winner: Player 2\n",
            "reward -1\n",
            "Current Player before the move: Player 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Check the Reward Condition"
      ],
      "metadata": {
        "id": "ILtC5QBGFJ3A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the Moving Condition"
      ],
      "metadata": {
        "id": "A5MZ9PCiFLaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the environment\n",
        "env = TicTacToeEnv()\n",
        "\n",
        "# Normal Move\n",
        "action = env.board_size * 5 + 5  # Convert 2D coordinate (5,5) to action\n",
        "env.step(action)\n",
        "# Check the updated state, neighbors, etc.\n",
        "\n",
        "# Move when cell is taken\n",
        "env.reset()\n",
        "env.state[5, 4] = 1  # Mark cell (5,4) as taken\n",
        "env.step(action)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6cxL3n_FNGo",
        "outputId": "eac93f55-b108-42ca-9ebc-22be0f67a60d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int8),\n",
              " 0,\n",
              " False,\n",
              " {})"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Hyperparameters**"
      ],
      "metadata": {
        "id": "R9jIzEOyjHtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up hyperparameters\n",
        "replay_buffer_max_length = 100  # @param {type:\"integer\"}这指定了重播缓冲区的最大长度。重播缓冲区用于存储过去的经验，以便代理可以从中学习。\n",
        "batch_size = 32  # @param {type:\"integer\"} 这指定了从重播缓冲区中提取的每个批次的大小，以进行训练。\n",
        "learning_rate = 1e-3  # @param {type:\"number\"}这是优化器的学习率，它影响了模型权重的更新速度。\n",
        "log_interval = 10  # @param {type:\"integer\"}这指定了日志记录间隔，用于监控训练过程。\n",
        "\n",
        "# Define the total number of training episodes\n",
        "total_episodes = 2  # Train for 100 episodes\n",
        "num_eval_episodes = 10  # @param {type:\"integer\"}这指定了每个评估周期中要运行的评估周期数。\n",
        "evaluation_interval = 10  # @param {type:\"integer\"}这指定了评估间隔，即在每次训练迭代之间进行模型评估的频率。\n",
        "update_target_network = 10  # Update target network every 100 episodes\n",
        "capture_video_every = 10  # Interval for capturing videos\n"
      ],
      "metadata": {
        "id": "8Nw76L7ZjI6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Network（Q**-Network）"
      ],
      "metadata": {
        "id": "urn4fU_8iKgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DQN(tf.keras.Model):\n",
        "    def __init__(self, state_size, action_size):\n",
        "        super(DQN, self).__init__()\n",
        "        self.dense1 = tf.keras.layers.Dense(24, activation='relu', input_shape=(state_size,))\n",
        "        self.dropout1 = tf.keras.layers.Dropout(0.2)\n",
        "        self.dense2 = tf.keras.layers.Dense(24, activation='relu')\n",
        "        self.dropout2 = tf.keras.layers.Dropout(0.2)\n",
        "        self.dense3 = tf.keras.layers.Dense(action_size, activation='linear')\n",
        "\n",
        "    def call(self, state):\n",
        "        x = self.dense1(state)\n",
        "        x = self.dropout1(x, training=True)\n",
        "        x = self.dense2(x)\n",
        "        x = self.dropout2(x, training=True)\n",
        "        return self.dense3(x)"
      ],
      "metadata": {
        "id": "CvDbkOPIiJk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Agent**"
      ],
      "metadata": {
        "id": "rMAO4SAeijQq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "agent for e-greedy policy"
      ],
      "metadata": {
        "id": "uIfMpSiPrTNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "# DQN代理\n",
        "class DDQNAgent:\n",
        "    def __init__(self, state_size, action_size, epsilon=1.0, epsilon_min=0.01, epsilon_decay=0.995):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.memory = ReplayBuffer(100000)\n",
        "        self.gamma = 0.95  # 折扣因子\n",
        "        self.model = DQN(state_size, action_size)\n",
        "        self.target_model = DQN(state_size, action_size)\n",
        "        self.update_target_model()\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "        self.policy = EpsilonGreedyPolicy(epsilon, epsilon_min, epsilon_decay, action_size)\n",
        "\n",
        "    def update_target_model(self):\n",
        "        self.target_model.set_weights(self.model.get_weights())\n",
        "\n",
        "    def act(self, state):\n",
        "        q_values = self.model.predict(state)\n",
        "        return self.policy.select_action(q_values)\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        self.memory.add(state, action, reward, next_state, done)\n",
        "\n",
        "    def replay(self, batch_size):\n",
        "        #Check if Memory is Sufficient:\n",
        "        if len(self.memory.buffer) < batch_size:\n",
        "            return\n",
        "\n",
        "        #Sampling from Replay Buffer:\n",
        "        minibatch = self.memory.sample(batch_size)\n",
        "\n",
        "        #Processing Each Sample:\n",
        "        for state, action, reward, next_state, done in minibatch:\n",
        "            target = self.model(state).numpy()\n",
        "            if done:\n",
        "                target[0][action] = reward\n",
        "            else:\n",
        "                t = self.target_model(next_state)[0]\n",
        "                target[0][action] = reward + self.gamma * np.amax(t)\n",
        "\n",
        "            #Training the Model:\n",
        "            with tf.GradientTape() as tape:\n",
        "                tape.watch(self.model.trainable_variables)\n",
        "                q_values = self.model(state)\n",
        "                loss = tf.keras.losses.MSE(target, q_values)\n",
        "            grads = tape.gradient(loss, self.model.trainable_variables)\n",
        "            self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
        "        #Epsilon Update:\n",
        "        self.policy.update_epsilon()\n",
        "\n",
        "        #if self.epsilon > self.epsilon_min:\n",
        "        #    self.epsilon *= self.epsilon_decay"
      ],
      "metadata": {
        "id": "p6BuIcLnilwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "agent for SARSA policy"
      ],
      "metadata": {
        "id": "ABgtlC6OrVrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SARSAAgent:\n",
        "    def __init__(self, state_size, action_size, epsilon=1.0, epsilon_min=0.01, epsilon_decay=0.995):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.memory = ReplayBuffer(100000)\n",
        "        self.gamma = 0.95  # Discount factor\n",
        "        self.model = DQN(state_size, action_size)\n",
        "        self.target_model = DQN(state_size, action_size)\n",
        "        self.update_target_model()\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "        self.policy = SARSAPolicy(epsilon, epsilon_min, epsilon_decay, action_size)\n",
        "\n",
        "    def compile_models(self, learning_rate=0.001):\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "        self.model.compile(optimizer=self.optimizer, loss=tf.keras.losses.MeanSquaredError())\n",
        "        self.target_model.compile(optimizer=self.optimizer, loss=tf.keras.losses.MeanSquaredError())\n",
        "\n",
        "\n",
        "    def update_target_model(self):\n",
        "        # Update weights\n",
        "        self.target_model.set_weights(self.model.get_weights())\n",
        "\n",
        "    def act(self, state):\n",
        "        # Action selection using SARSA policy\n",
        "        return self.policy.select_action(state, self.model)\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        # Store experience in memory\n",
        "        self.memory.add(state, action, reward, next_state, done)\n",
        "\n",
        "    def replay(self, batch_size):\n",
        "        if len(self.memory.buffer) < batch_size:\n",
        "            return\n",
        "\n",
        "        minibatch = self.memory.sample(batch_size)\n",
        "        for state, action, reward, next_state, done in minibatch:\n",
        "            target = self.model.predict(state)[0]\n",
        "            if done:\n",
        "                target[action] = reward\n",
        "            else:\n",
        "                # SARSA: Use current policy to select the next action\n",
        "                next_action = self.policy.select_action(next_state, self.model)\n",
        "                target_q = self.target_model.predict(next_state)[0][next_action]\n",
        "                target[action] = reward + self.gamma * target_q\n",
        "\n",
        "            target_f = self.model.predict(state)\n",
        "            target_f[0][action] = target[action]\n",
        "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
        "\n",
        "        self.policy.update_epsilon()\n"
      ],
      "metadata": {
        "id": "6zzPGzl2rYmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **策略**"
      ],
      "metadata": {
        "id": "WCObzZg9u9en"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**e-greedy policy**"
      ],
      "metadata": {
        "id": "AkvLSqCLpo-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "class EpsilonGreedyPolicy:\n",
        "    def __init__(self, epsilon, epsilon_min, epsilon_decay, action_size):\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_min = epsilon_min\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.action_size = action_size\n",
        "\n",
        "    def select_action(self, q_values):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return random.randrange(self.action_size)\n",
        "        else:\n",
        "            return np.argmax(q_values)\n",
        "\n",
        "    def update_epsilon(self):\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n"
      ],
      "metadata": {
        "id": "8JKzpixAu-xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SARSA policy**"
      ],
      "metadata": {
        "id": "BUNM1SLfpuv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SARSAPolicy:\n",
        "    def __init__(self, epsilon, epsilon_min, epsilon_decay, action_size):\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_min = epsilon_min\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.action_size = action_size\n",
        "\n",
        "    def select_action(self, state, model):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.randint(self.action_size)\n",
        "        else:\n",
        "            q_values = model.predict(state)\n",
        "            return np.argmax(q_values[0])\n",
        "\n",
        "    def update_epsilon(self):\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n"
      ],
      "metadata": {
        "id": "5c_eK2F9pojL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **reply buffer**\n",
        "\n",
        "为了跟踪从环境中收集的数据，我们将使用 Reverb，这是 Deepmind 的一个高效、可扩展且易于使用的reply system。 当我们收集trajectories时，它会存储经验数据并在训练期间消耗。此replay buffer是使用描述要存储的tensors的规范构建的，可以使用 agent.collect_data_spec 从代理获取tensor"
      ],
      "metadata": {
        "id": "ac6fRm5dxMvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "创建 Replay Buffer:\n",
        "'''\n",
        "from collections import deque\n",
        "\n",
        "# Your existing code for ReplayBuffer and other classes\n",
        "class ReplayBuffer:\n",
        "    def __init__(self, buffer_size):\n",
        "        self.buffer = deque(maxlen=buffer_size)\n",
        "\n",
        "    def add(self, state, action, reward, next_state, done):\n",
        "        self.buffer.append((state, action, reward, next_state, done))\n",
        "    def __len__(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.buffer, batch_size)\n"
      ],
      "metadata": {
        "id": "py05NVSbxVtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **评估**"
      ],
      "metadata": {
        "id": "S2sZOzt5i0BK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_avg_return(environment, agent, num_episodes=10):\n",
        "    # Store the original epsilon value\n",
        "    original_epsilon = agent.policy.epsilon\n",
        "\n",
        "    # Set epsilon to 0 to disable exploration\n",
        "    agent.policy.epsilon = 0\n",
        "\n",
        "    total_return = 0.0\n",
        "    for _ in range(num_episodes):\n",
        "        state = environment.reset()\n",
        "        state = np.reshape(state, [1, environment.state_size])\n",
        "        episode_return = 0.0\n",
        "        while True:\n",
        "            action = agent.act(state)\n",
        "            state, reward, done, _ = environment.step(action)\n",
        "            state = np.reshape(state, [1, environment.state_size])\n",
        "            episode_return += reward\n",
        "            if done:\n",
        "                break\n",
        "        total_return += episode_return\n",
        "\n",
        "    # Restore the original epsilon value\n",
        "    agent.policy.epsilon = original_epsilon\n",
        "    return total_return\n"
      ],
      "metadata": {
        "id": "ule_Zfxsi1bX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **训练**"
      ],
      "metadata": {
        "id": "pyBKRPMCiuVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "# Assuming DDQNAgent and TicTacToeEnv are defined and initialized"
      ],
      "metadata": {
        "id": "vK3fn8DnDdg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_video(frames, filename='training_video.mp4', fps=10):\n",
        "    if not frames:\n",
        "        print(\"No frames to create video.\")\n",
        "        return\n",
        "    height, width, _ = frames[0].shape\n",
        "    video = cv2.VideoWriter(filename, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "    for frame in frames:\n",
        "        video.write(frame)\n",
        "    video.release()"
      ],
      "metadata": {
        "id": "EFDZ4-U_A3_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = TicTacToeEnv()\n",
        "agent = DDQNAgent(state_size=env.state_size, action_size=env.action_size)\n",
        "frames = []\n",
        "all_frames = []  # To store frames for the complete video\n",
        "# Variables to track the number of wins and draws\n",
        "player_1_wins = 0\n",
        "player_2_wins = 0\n",
        "draws = 0\n",
        "\n",
        "for episode in range(total_episodes):\n",
        "    state = env.reset()\n",
        "    state = np.reshape(state, [1, env.state_size])\n",
        "    avg_reward = 0\n",
        "    episode_frames = []  # To store frames for the current episode\n",
        "\n",
        "    while True:\n",
        "        action = agent.act(state)\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        frame = env.render(mode='rgb_array')\n",
        "        if frame is not None:\n",
        "            episode_frames.append(frame)\n",
        "            all_frames.append(frame)  # Also add to the complete video frames list\n",
        "\n",
        "        next_state = np.reshape(next_state, [1, env.state_size])\n",
        "        agent.remember(state, action, reward, next_state, done)\n",
        "        state = next_state\n",
        "\n",
        "        if done:\n",
        "            winner = env.check_winner()\n",
        "            if winner == 1:\n",
        "                player_1_wins += 1\n",
        "            elif winner == -1:\n",
        "                player_2_wins += 1\n",
        "            else:\n",
        "                draws += 1\n",
        "            break\n",
        "        if len(agent.memory) > batch_size:\n",
        "            agent.replay(batch_size)\n",
        "        if done:\n",
        "            break\n",
        "    print(f\"Captured {len(episode_frames)} frames in Episode {episode + 1}\")\n",
        "\n",
        "    # Evaluate average reward every 'evaluation_interval' episodes\n",
        "    if (episode + 1) % evaluation_interval == 0:\n",
        "        avg_reward = compute_avg_return(env, agent, num_eval_episodes)\n",
        "        print(f\"Episode: {episode + 1}, Average Reward: {avg_reward}\")\n",
        "\n",
        "    # Create video for the current episode\n",
        "    if episode_frames and (episode + 1) % capture_video_every == 0:\n",
        "        create_video(episode_frames, filename=f'training_video_episode_{episode+1}.mp4')\n",
        "        print(f\"Video created for Episode {episode + 1}\")\n",
        "\n",
        "\n",
        "# Create a complete video after all episodes\n",
        "if all_frames:\n",
        "    create_video(all_frames, filename='complete_training_video.mp4')\n",
        "    print(\"Complete training video created\")\n",
        "else:\n",
        "    print(\"No frames to create the complete video.\")\n",
        "\n",
        "# After all episodes\n",
        "print(f\"Player 1 Wins: {player_1_wins}, Player 2 Wins: {player_2_wins}, Draws: {draws}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pREXVBxmVoe",
        "outputId": "e1cd731e-1eba-42bd-8c54-438aefe516eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 245ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 173ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 107ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Captured 167 frames in Episode 1\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Captured 27 frames in Episode 2\n",
            "Complete training video created\n",
            "Player 1 Wins: 2, Player 2 Wins: 0, Draws: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = TicTacToeEnv()\n",
        "agent = DDQNAgent(state_size=env.state_size, action_size=env.action_size)\n",
        "frames = []\n",
        "all_frames = []  # To store frames for the complete video\n",
        "\n",
        "# Variables to track the number of wins and draws\n",
        "player_1_wins = 0\n",
        "player_2_wins = 0\n",
        "draws = 0\n",
        "total_reward_all_episodes = 0  # Total reward across all episodes\n",
        "\n",
        "for episode in range(total_episodes):\n",
        "    state = env.reset()\n",
        "    state = np.reshape(state, [1, env.state_size])\n",
        "    episode_reward = 0  # Reward for the current episode\n",
        "    episode_frames = []  # To store frames for the current episode\n",
        "\n",
        "    while True:\n",
        "        action = agent.act(state)\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        frame = env.render(mode='rgb_array')\n",
        "        if frame is not None:\n",
        "            episode_frames.append(frame)\n",
        "            all_frames.append(frame)  # Also add to the complete video frames list\n",
        "\n",
        "        next_state = np.reshape(next_state, [1, env.state_size])\n",
        "        agent.remember(state, action, reward, next_state, done)\n",
        "        state = next_state\n",
        "        episode_reward += reward  # Accumulate reward for the current episode\n",
        "\n",
        "        if done:\n",
        "            winner = env.check_winner()\n",
        "            if winner == 1:\n",
        "                player_1_wins += 1\n",
        "            elif winner == -1:\n",
        "                player_2_wins += 1\n",
        "            else:\n",
        "                draws += 1\n",
        "            break\n",
        "\n",
        "        if len(agent.memory) > batch_size:\n",
        "            agent.replay(batch_size)\n",
        "\n",
        "    # Update total reward across all episodes\n",
        "    total_reward_all_episodes += episode_reward\n",
        "\n",
        "    # Print summary of the episode\n",
        "    print(f\"Episode {episode + 1} finished. Player 1 Wins: {player_1_wins}, Player 2 Wins: {player_2_wins}, Draws: {draws}, Episode Reward: {episode_reward}\")\n",
        "\n",
        "    # Create video for the current episode\n",
        "    if episode_frames and (episode + 1) % capture_video_every == 0:\n",
        "        create_video(episode_frames, filename=f'training_video_episode_{episode+1}.mp4')\n",
        "        print(f\"Video created for Episode {episode + 1}\")\n",
        "\n",
        "# Create a complete video after all episodes\n",
        "if all_frames:\n",
        "    create_video(all_frames, filename='complete_training_video.mp4')\n",
        "    print(\"Complete training video created\")\n",
        "else:\n",
        "    print(\"No frames to create the complete video.\")\n",
        "\n",
        "# Print final summary\n",
        "print(f\"Total Episodes: {total_episodes}, Player 1 Wins: {player_1_wins}, Player 2 Wins: {player_2_wins}, Draws: {draws}, Total Reward: {total_reward_all_episodes}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wF-6HYztPdI7",
        "outputId": "f0442f25-5af3-4338-b321-3a05cb37d6b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 637ms/step\n",
            "1/1 [==============================] - 0s 88ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Episode 1 finished. Player 1 Wins: 1, Player 2 Wins: 0, Draws: 0, Episode Reward: 1\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Episode 2 finished. Player 1 Wins: 1, Player 2 Wins: 1, Draws: 0, Episode Reward: -1\n",
            "Complete training video created\n",
            "Total Episodes: 2, Player 1 Wins: 1, Player 2 Wins: 1, Draws: 0, Total Reward: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "training SARSA agent using SARSA policy"
      ],
      "metadata": {
        "id": "gkeumN96r-4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def moving_average(x, w):\n",
        "    return np.convolve(x, np.ones(w), 'valid') / w"
      ],
      "metadata": {
        "id": "FcQb6mGjsCJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "env = TicTacToeEnv()\n",
        "agent = SARSAAgent(state_size=env.state_size, action_size=env.action_size)\n",
        "frames = []\n",
        "all_frames = []  # To store frames for the complete video\n",
        "agent.compile_models(learning_rate=0.001)\n",
        "\n",
        "# Variables to track the number of wins and draws\n",
        "player_1_wins = 0\n",
        "player_2_wins = 0\n",
        "draws = 0\n",
        "total_reward_all_episodes = 0  # Total reward across all episodes\n",
        "train_every_n_steps = 10  # Define how often you want to train\n",
        "step_counter = 0  # Keep track of steps\n",
        "\n",
        "\n",
        "for episode in range(total_episodes):\n",
        "    state = env.reset()\n",
        "    state = np.reshape(state, [1, env.state_size])\n",
        "    episode_reward = 0  # Reward for the current episode\n",
        "    episode_frames = []  # To store frames for the current episode\n",
        "\n",
        "    while True:\n",
        "        action = agent.act(state)\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        frame = env.render(mode='rgb_array')\n",
        "        if frame is not None:\n",
        "            episode_frames.append(frame)\n",
        "            all_frames.append(frame)\n",
        "\n",
        "        next_state = np.reshape(next_state, [1, env.state_size])\n",
        "        agent.remember(state, action, reward, next_state, done)\n",
        "        state = next_state\n",
        "        episode_reward += reward  # Accumulate reward for the current episode\n",
        "\n",
        "        if len(agent.memory) > batch_size and step_counter % train_every_n_steps == 0:\n",
        "            agent.replay(batch_size)\n",
        "        step_counter += 1\n",
        "\n",
        "        if done:\n",
        "            winner = env.check_winner()\n",
        "            if winner == 1:\n",
        "                player_1_wins += 1\n",
        "            elif winner == -1:\n",
        "                player_2_wins += 1\n",
        "            else:\n",
        "                draws += 1\n",
        "            break\n",
        "\n",
        "    print(f\"Captured {len(episode_frames)} frames in Episode {episode + 1}\")\n",
        "    #total_rewards.append(total_reward)\n",
        "    # Episode summary\n",
        "    print(f\"Episode {episode + 1} finished. Player 1 Wins: {player_1_wins}, Player 2 Wins: {player_2_wins}, Draws: {draws}, Episode Reward: {episode_reward}\")\n",
        "\n",
        "    # Create video for the current episode\n",
        "    if episode_frames and (episode + 1) % capture_video_every == 0:\n",
        "        create_video(episode_frames, filename=f'training_video_episode_{episode+1}.mp4')\n",
        "        print(f\"Video created for Episode {episode + 1}\")\n",
        "\n",
        "# Create a complete video after all episodes\n",
        "if all_frames:\n",
        "    create_video(all_frames, filename='complete_training_video_SARSA_agent.mp4')\n",
        "    print(\"Complete training video created\")\n",
        "else:\n",
        "    print(\"No frames to create the complete video.\")\n",
        "\n",
        "# Print final summary\n",
        "print(f\"Total Episodes: {total_episodes}, Player 1 Wins: {player_1_wins}, Player 2 Wins: {player_2_wins}, Draws: {draws}, Total Reward: {total_reward_all_episodes}\")\n"
      ],
      "metadata": {
        "id": "opr7FMeqsDBj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d453ea1-74ce-4f08-d7e5-012e8d446016"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Captured 39 frames in Episode 1\n",
            "Episode 1 finished. Player 1 Wins: 1, Player 2 Wins: 0, Draws: 0, Episode Reward: 1\n",
            "1/1 [==============================] - 0s 157ms/step\n",
            "1/1 [==============================] - 0s 150ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 86ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Captured 36 frames in Episode 2\n",
            "Episode 2 finished. Player 1 Wins: 1, Player 2 Wins: 1, Draws: 0, Episode Reward: -1\n",
            "Complete training video created\n",
            "Total Episodes: 2, Player 1 Wins: 1, Player 2 Wins: 1, Draws: 0, Total Reward: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12, 6))  # Set the figure size\n",
        "plt.plot(total_reward_all_episodes, label='Total Reward per Episode')  # Plot the total rewards\n",
        "plt.xlabel('Episodes')  # Label for x-axis\n",
        "plt.ylabel('Total Reward')  # Label for y-axis\n",
        "plt.title('Total Reward per Episode Over Time')  # Title of the plot\n",
        "plt.legend()  # Add a legend\n",
        "plt.grid(True)  # Add grid for better readability\n",
        "plt.show()  # Display the plot\n"
      ],
      "metadata": {
        "id": "dMkpU3_usRUn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "44c07357-bf87-41ff-dc94-aa5dcc98c53c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/0AAAIjCAYAAABRfHuLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABaQklEQVR4nO3deXxMZ///8fdkX0hCJCIEsa+ljdIoDRWi2mpKbdVaGnShVEiLtrYu6YJS1NKFLnpT2uqGNnYqaAWtItXFLkGJILJIzu8Pv8y3IwmJJpKcvJ6PxzxqrnOdM59r5prc93vOZjEMwxAAAAAAADAdu+IuAAAAAAAAFA1CPwAAAAAAJkXoBwAAAADApAj9AAAAAACYFKEfAAAAAACTIvQDAAAAAGBShH4AAAAAAEyK0A8AAAAAgEkR+gEAAAAAMClCPwCg1Fm/fr0sFovWr19f3KWUCBaLRRMnTizuMorFwoULZbFYdPDgwZv6umX5PS+omjVrasCAAcVdBgCUWYR+AEC+WCyWfD3yE8RfffVVLV++vMhrzg6E2Q8HBwdVrVpVAwYM0LFjx4r89WEr+8eavB6LFy8u7hKLVUZGht5++23dfvvtKl++vMqVK6fbb79db7/9tjIyMoq7PKvrfY7/fgAAip9DcRcAACgdPv74Y5vnH330kWJiYnK0N2zY8LrbevXVV/XQQw8pPDy8MEvM0+TJkxUYGKjU1FRt3bpVCxcu1ObNm7Vnzx65uLjclBrwf4YPH67bb789R3twcHCBt/Xoo4+qd+/ecnZ2LozSis3Fixd17733asOGDbrvvvs0YMAA2dnZadWqVRoxYoS++OILfffdd3J3dy/uUtWwYcMc3/uxY8eqXLlyev7553P0j4+Pl50d+5kAoLgQ+gEA+fLII4/YPN+6datiYmJytJdE99xzj1q0aCFJGjRokCpVqqTXX39dX3/9tXr27FnM1V3fxYsXS0TYy4/81Nq2bVs99NBDhfJ69vb2sre3L5RtFafIyEht2LBBM2fO1LBhw6ztTz75pGbPnq1hw4Zp9OjRmjNnzk2ryTAMpaamytXV1aa9cuXKOb73r732mipVqpTr34PS/oMMAJR2/OwKACg0Fy9e1KhRoxQQECBnZ2fVr19fU6ZMkWEY1j4Wi0UXL17Uhx9+aD0EOPt830OHDumpp55S/fr15erqKm9vb/Xo0aPQz9du27atJOnPP/+0ad+/f78eeughVaxYUS4uLmrRooW+/vpr6/KkpCTZ29vr7bfftradPn1adnZ28vb2thnnk08+KT8/P+vzTZs2qUePHqpevbqcnZ0VEBCgkSNH6tKlSzY1DBgwQOXKldOff/6pLl26qHz58urbt68kKS0tTSNHjpSPj4/Kly+vrl276ujRo/kac/Yh2UuWLNG4cePk5+cnd3d3de3aVUeOHMnRf9u2bercubM8PT3l5uamkJAQ/fjjjzZ9Jk6cKIvFor179+rhhx9WhQoV1KZNm3zVcz0Wi0XDhg3TokWLVL9+fbm4uCgoKEgbN2606ZfbOf0///yzwsLCVKlSJbm6uiowMFCPPfaYzXr5matSwd7zY8eO6bHHHlPlypXl7Oysxo0b64MPPrjuWI8ePar3339fd999t03gzzZ06FC1b99e7733nvW1mzRpovbt2+fom5WVpapVq9r8qJKVlaXp06ercePGcnFxUeXKlfX444/r7NmzNuvWrFlT9913n77//nu1aNFCrq6umjdv3nXrv56rz+nP/sw2b96s4cOHy8fHR15eXnr88ceVnp6upKQk9evXTxUqVFCFChX07LPP5vhc8jsmAAB7+gEAhcQwDHXt2lXr1q1TRESEmjdvru+//15RUVE6duyY3nrrLUlXThMYNGiQWrZsqSFDhkiSateuLUn66aeftGXLFvXu3VvVqlXTwYMHNWfOHLVr10579+6Vm5tbodSaHRArVKhgbfvtt9905513qmrVqhozZozc3d312WefKTw8XJ9//rkefPBBeXl5qUmTJtq4caOGDx8uSdq8ebMsFovOnDmjvXv3qnHjxpKuhPzsHxckaenSpUpJSdGTTz4pb29vbd++XTNnztTRo0e1dOlSm/ouX76ssLAwtWnTRlOmTLGOe9CgQfrkk0/08MMPq3Xr1lq7dq3uvffeAo39lVdekcVi0XPPPaeTJ09q+vTpCg0N1a5du6x7dNeuXat77rlHQUFBmjBhguzs7LRgwQLdfffd2rRpk1q2bGmzzR49eqhu3bp69dVXc4Sz3Jw/f16nT5/O0e7t7W1zHviGDRu0ZMkSDR8+XM7OznrnnXfUuXNnbd++XU2aNMl12ydPnlSnTp3k4+OjMWPGyMvLSwcPHtQXX3xh7ZPfuSrl/z1PTEzUHXfcYf2xwsfHRytXrlRERISSk5P1zDPP5Pl+rFy5UpmZmerXr1+effr166d169Zp1apVGjRokHr16qWJEycqISHB5selzZs36/jx4+rdu7e17fHHH9fChQs1cOBADR8+XH///bdmzZqlnTt36scff5Sjo6O1b3x8vPr06aPHH39cgwcPVv369fOs6b96+umn5efnp0mTJmnr1q2aP3++vLy8tGXLFlWvXl2vvvqqVqxYoTfffFNNmjSxeX8KMiYAKPMMAABuwNChQ41//8/I8uXLDUnGyy+/bNPvoYceMiwWi/HHH39Y29zd3Y3+/fvn2GZKSkqOttjYWEOS8dFHH1nb1q1bZ0gy1q1bd80aFyxYYEgyVq9ebZw6dco4cuSIsWzZMsPHx8dwdnY2jhw5Yu3boUMHo2nTpkZqaqq1LSsry2jdurVRt25dm3FXrlzZ+jwyMtK46667DF9fX2POnDmGYRjGP//8Y1gsFmPGjBnXHFt0dLRhsViMQ4cOWdv69+9vSDLGjBlj03fXrl2GJOOpp56yaX/44YcNScaECROu+V5kv2dVq1Y1kpOTre2fffaZIclaa1ZWllG3bl0jLCzMyMrKsqk/MDDQ6Nixo7VtwoQJhiSjT58+13ztq2vI63HixAlr3+y2n3/+2dp26NAhw8XFxXjwwQetbdmf8d9//20YhmF8+eWXhiTjp59+yrOO/M7VgrznERERRpUqVYzTp0/b9O3du7fh6emZ6+ef7ZlnnjEkGTt37syzT1xcnCHJiIyMNAzDMOLj4w1JxsyZM236PfXUU0a5cuWsr7dp0yZDkrFo0SKbfqtWrcrRXqNGDUOSsWrVqjzryEvjxo2NkJCQXJfVqFHD5vue/ZldPceCg4MNi8ViPPHEE9a2y5cvG9WqVbPZdkHGBAAwDA7vBwAUihUrVsje3t66BzzbqFGjZBiGVq5ced1t/Pvc4YyMDP3zzz+qU6eOvLy8FBcXd8O1hYaGysfHRwEBAXrooYfk7u6ur7/+WtWqVZMknTlzRmvXrlXPnj2te6FPnz6tf/75R2FhYTpw4ID1av9t27ZVYmKi4uPjJV3Zo3/XXXepbdu22rRpk6Qre1sNw7DZ0//vsV28eFGnT59W69atZRiGdu7cmaPmJ5980ub5ihUrJCnH+3utPci56devn8qXL299/tBDD6lKlSrW7e/atUsHDhzQww8/rH/++cf6Xly8eFEdOnTQxo0blZWVZbPNJ554okA1jB8/XjExMTkeFStWtOkXHBysoKAg6/Pq1avrgQce0Pfff6/MzMxct+3l5SVJ+vbbb/O84n1+52p+33PDMPT555/r/vvvl2EY1vfs9OnTCgsL07lz5645f8+fPy9JNp/L1bKXJScnS5Lq1aun5s2ba8mSJdY+mZmZWrZsme6//37rfFu6dKk8PT3VsWNHm7qCgoJUrlw5rVu3zuZ1AgMDFRYWlmcdhSkiIsLmyI5WrVrJMAxFRERY2+zt7dWiRQv99ddf1raCjgkAyjoO7wcAFIpDhw7J398/R3DJvpr/oUOHrruNS5cuKTo6WgsWLNCxY8dsDhU/d+7cDdc2e/Zs1atXT+fOndMHH3ygjRs32lxc7I8//pBhGHrxxRf14osv5rqNkydPqmrVqtYgv2nTJlWrVk07d+7Uyy+/LB8fH02ZMsW6zMPDQ82aNbOuf/jwYY0fP15ff/11jvOOrx6bg4OD9QeJbIcOHZKdnZ31VIhsBT38um7dujbPLRaL6tSpYz3l4cCBA5Kk/v3757mNc+fO2ZwaERgYWKAamjZtqtDQ0ALXKl0JuykpKTp16pTNYe3ZQkJC1L17d02aNElvvfWW2rVrp/DwcD388MPWzzy/czW/7/mpU6eUlJSk+fPna/78+bmO5eTJk3mOM7uO7PCfm9x+GOjVq5fGjRunY8eOqWrVqlq/fr1OnjypXr16WfscOHBA586dk6+vb77qKuhn+V9Ur17d5rmnp6ckKSAgIEf7v78zBR0TAJR1hH4AQInx9NNPa8GCBXrmmWcUHBwsT09PWSwW9e7dO8fe5YJo2bKl9er94eHhatOmjR5++GHFx8erXLly1m2PHj06z72cderUkST5+/srMDBQGzduVM2aNWUYhoKDg+Xj46MRI0bo0KFD2rRpk1q3bm29TVlmZqY6duyoM2fO6LnnnlODBg3k7u6uY8eOacCAATnG5uzsXGy3OMuu5c0331Tz5s1z7VOuXDmb51df3b04WSwWLVu2TFu3btU333yj77//Xo899pimTp2qrVu35qi9MGS/Z4888kieP5bccsstea6f/WPDL7/8kud7/ssvv0iSGjVqZG3r1auXxo4dq6VLl+qZZ57RZ599Jk9PT3Xu3NmmNl9fXy1atCjX7fr4+Ng8v5mfZV53Xcit/d8/ABZ0TABQ1hH6AQCFokaNGlq9erXOnz9vszdy//791uXZ/n1I778tW7ZM/fv319SpU61tqampSkpKKrQ67e3tFR0drfbt22vWrFkaM2aMatWqJUlydHTM1x7otm3bauPGjQoMDFTz5s1Vvnx5NWvWTJ6enlq1apXi4uI0adIka/9ff/1Vv//+uz788EObi5HFxMTku+4aNWooKytLf/75p82e5uzTDPIre09+NsMw9Mcff1hDafZebQ8Pj3y9F0Xp6lol6ffff5ebm9t1g90dd9yhO+64Q6+88oo+/fRT9e3bV4sXL9agQYPyPVfz+55nX9k/MzPzht6ze+65R/b29vr444/zvJjfRx99JAcHB5tAHxgYqJYtW2rJkiUaNmyYvvjiC4WHh9scxVK7dm2tXr1ad955Z4n6cea/MOOYAKAocU4/AKBQdOnSRZmZmZo1a5ZN+1tvvSWLxaJ77rnH2ubu7p5rkLe3t89x9feZM2fmef72jWrXrp1atmyp6dOnKzU1Vb6+vmrXrp3mzZunEydO5Oh/6tQpm+dt27bVwYMHtWTJEuvh/nZ2dmrdurWmTZumjIwMm/P5s/dc/ntshmFoxowZ+a45+/379+0CJWn69On53oZ0JTz++zDyZcuW6cSJE9btBwUFqXbt2poyZYouXLiQY/2r34uiFBsba3Mu/JEjR/TVV1+pU6dOee4lPnv2bI45lL33PC0tTVL+52p+33N7e3t1795dn3/+ufbs2ZOjpuu9ZwEBARo4cKBWr16tOXPm5Fg+d+5crV27VhERETlO++jVq5e2bt2qDz74QKdPn7Y5tF+SevbsqczMTL300ks5tnv58uVC/UHtZjHjmACgKLGnHwBQKO6//361b99ezz//vA4ePKhmzZrphx9+0FdffaVnnnnG5rzooKAgrV69WtOmTbMeLt+qVSvdd999+vjjj+Xp6alGjRopNjZWq1evlre3d6HXGxUVpR49emjhwoV64oknNHv2bLVp00ZNmzbV4MGDVatWLSUmJio2NlZHjx7V7t27retmB/r4+Hi9+uqr1va77rpLK1eulLOzs26//XZre4MGDVS7dm2NHj1ax44dk4eHhz7//PMC3VO8efPm6tOnj9555x2dO3dOrVu31po1a/THH38UaNwVK1ZUmzZtNHDgQCUmJmr69OmqU6eOBg8eLOnKjxfvvfee7rnnHjVu3FgDBw5U1apVdezYMa1bt04eHh765ptvCvSaV9u0aZNSU1NztN9yyy02h8E3adJEYWFhNrfsk2RzFMXVPvzwQ73zzjt68MEHVbt2bZ0/f17vvvuuPDw81KVLF0n5n6sFec9fe+01rVu3Tq1atdLgwYPVqFEjnTlzRnFxcVq9erXOnDlzzffkrbfe0v79+/XUU09p1apV1j3633//vb766iuFhITYHAGTrWfPnho9erRGjx6tihUr5jjSICQkRI8//riio6O1a9cuderUSY6Ojjpw4ICWLl2qGTNm6KGHHrpmbSWNGccEAEXq5t8wAABgBlffss8wDOP8+fPGyJEjDX9/f8PR0dGoW7eu8eabb9rclsswDGP//v3GXXfdZbi6uhqSrLfzOnv2rDFw4ECjUqVKRrly5YywsDBj//79OW75VdBb9uV2+7bMzEyjdu3aRu3atY3Lly8bhmEYf/75p9GvXz/Dz8/PcHR0NKpWrWrcd999xrJly3Ks7+vra0gyEhMTrW2bN282JBlt27bN0X/v3r1GaGioUa5cOaNSpUrG4MGDjd27dxuSjAULFlj79e/f33B3d891PJcuXTKGDx9ueHt7G+7u7sb9999vHDlypEC37Pvf//5njB071vD19TVcXV2Ne++91+aWgdl27txpdOvWzfD29jacnZ2NGjVqGD179jTWrFlj7ZN9y75Tp05d87WvriGvx7/HIMkYOnSo8cknnxh169Y1nJ2djVtvvTXHZ371Lfvi4uKMPn36GNWrVzecnZ0NX19f47777rO59Z9h5H+uFuQ9T0xMNIYOHWoEBAQYjo6Ohp+fn9GhQwdj/vz5+Xp/0tLSjLfeessICgoy3N3dDTc3N+O2224zpk+fbqSnp+e53p133mlIMgYNGpRnn/nz5xtBQUGGq6urUb58eaNp06bGs88+axw/ftzap0aNGsa9996br1qvdiO37Lv6e5nXfMrrO5GfMQEADMNiGFcdAwcAAExn/fr1at++vZYuXVoq9oJaLBYNHTo0xyH4AACgYDinHwAAAAAAkyL0AwAAAABgUoR+AAAAAABMinP6AQAAAAAwKfb0AwAAAABgUoR+AAAAAABMyqG4CzCDrKwsHT9+XOXLl5fFYinucgAAAAAAJmcYhs6fPy9/f3/Z2eW9P5/QXwiOHz+ugICA4i4DAAAAAFDGHDlyRNWqVctzOaG/EJQvX17SlTfbw8OjmKvBzZKRkaEffvhBnTp1kqOjY3GXA+TAHEVpwDxFScccRUnHHC27kpOTFRAQYM2jeSH0F4LsQ/o9PDwI/WVIRkaG3Nzc5OHhwR9YlEjMUZQGzFOUdMxRlHTMUVzvFHMu5AcAAAAAgEkR+gEAAAAAMClCPwAAAAAAJsU5/QAAAADyZBiGLl++rMzMzOIuBbnIyMiQg4ODUlNT+YxMxt7eXg4ODv/5tvCEfgAAAAC5Sk9P14kTJ5SSklLcpSAPhmHIz89PR44c+c/hECWPm5ubqlSpIicnpxveBqEfAAAAQA5ZWVn6+++/ZW9vL39/fzk5OREqS6CsrCxduHBB5cqVk50dZ2+bhWEYSk9P16lTp/T333+rbt26N/z5EvoBAAAA5JCenq6srCwFBATIzc2tuMtBHrKyspSeni4XFxdCv8m4urrK0dFRhw4dsn7GN4JZAQAAACBPBEmg+BTG949vMAAAAAAAJkXoBwAAAADApAj9AAAAAPAfWSwWLV++vLjLKDLt2rXTM888U9xlFKqFCxfKy8urSF+jZs2amj59epG+xvUQ+gEAAACYhsViueZj4sSJea578OBBWSwW7dq1q9DrGjBggLUGR0dHBQYG6tlnn1Vqamqhv1ZZULNmzVw/39deey3f2+jVq5d+//33IqyyZODq/QAAAABM48SJE9Z/L1myROPHj1d8fLy1rVy5csVRliSpc+fOWrBggTIyMrRjxw71799fFotFr7/+erHV9G+GYSgzM1MODiUnJmZkZMjR0THXZZMnT9bgwYNt2sqXL5/vbbu6usrV1fU/1VcasKcfAAAAQL4YhqGU9MvF8jAMI181+vn5WR+enp6yWCzW576+vpo2bZqqVasmZ2dnNW/eXKtWrbKuGxgYKEm69dZbZbFY1K5dO0nSTz/9pI4dO6pSpUry9PRUSEiI4uLiCvz+OTs7y8/PTwEBAQoPD1doaKhiYmKsy7OyshQdHa3AwEC5urqqWbNmWrZsmXV5ixYtNGXKFOvz8PBwOTs768KFC5Kko0ePymKx6I8//pAkffzxx2rRooXKly8vPz8/Pfzwwzp58qR1/fXr18tisWjlypUKCgqSs7OzNm/erIsXL6pfv34qV66cqlSpoqlTp153bBMnTlTz5s01b948620ee/bsqXPnztn0e++999SwYUO5uLioQYMGeuedd6zLso+0WLJkiUJCQuTi4qJFixbl+ZrZ4/r3w93d3WZs3333nW655Ra5uLjojjvu0J49e6zrX314/+7du9W+fXuVL19eHh4eCgoK0s8//2xd/vnnn6tx48ZydnZWzZo1c7wvJ0+e1P333y9XV1cFBgbmWntSUpIGDRokHx8feXh46O6779bu3buv+/7+FyXnJxwAAAAAJdqljEw1Gv99sbz23slhcnP6b/FlxowZmjp1qubNm6dbb71VH3zwgbp27arffvtNdevW1fbt29WyZUutXr1ajRs3lpOTkyTp/Pnz6t+/v2bOnCnDMDR16lR16dJFBw4cKNCe5X/bs2ePtmzZoho1aljboqOj9cknn2ju3LmqW7euNm7cqEceeUQ+Pj4KCQlRSEiI1q9fr9GjR8swDG3atEleXl7aunWrunXrpg0bNqhq1aqqU6eOpCt7yV966SXVr19fJ0+eVGRkpAYMGKAVK1bY1DJmzBhNmTJFtWrVUoUKFRQVFaUNGzboq6++kq+vr8aNG6e4uDg1b978mmP6448/9Nlnn+mbb75RcnKyIiIi9NRTT1nD76JFizR+/HjNmjVLt956q3bu3KnBgwfL3d1d/fv3t6ln6tSpuvXWW2/43vTZoqKiNGPGDPn5+WncuHG6//779fvvv+d69EDfvn116623as6cObK3t9euXbus/Xbs2KGePXtq4sSJ6tWrl7Zs2aKnnnpK3t7eGjBggKQrp3AcP35c69atk6Ojo4YPH27zI4sk9ejRQ66urlq5cqU8PT01b948dejQQb///rsqVqz4n8aaF0I/AAAAgDJhypQpeu6559S7d29J0uuvv65169Zp+vTpmj17tnx8fCRJ3t7e8vPzs653991322xn/vz58vLy0oYNG3Tffffl+/W//fZblStXTpcvX1ZaWprs7Ow0a9YsSVJaWppeffVVrV69WsHBwZKkWrVqafPmzZo3b55CQkLUrl07vf/++8rMzNSePXvk5OSknj17avPmzerWrZvWr1+vkJAQ6+s99thj1n/XqlVLb7/9tm6//XZduHDB5jSHyZMnq2PHjpKkCxcu6P3339cnn3yiDh06SJI+/PBDVatW7brjS01N1UcffaSqVatKkmbOnKl7771XU6dOlZ+fnyZMmKCpU6eqW7dukq4cWbF3717NmzfPJvQ/88wz1j7X8txzz+mFF16waVu5cqXatm1rfT5hwgTr2LLH8eWXX6pnz545tnf48GFFRUWpQYMGkqS6detal02bNk0dOnTQiy++KEmqV6+e9u7dqzfffFMDBgzQ77//rpUrV2r79u26/fbbJUnvv/++GjZsaN3G5s2btX37dp08eVLOzs6SrszJ5cuXa9myZRoyZMh1x3wjCP0AAAAA8sXV0V57J4cV22v/F8nJyTp+/LjuvPNOm/Y777zzuodXJyYm6oUXXtD69et18uRJZWZmKiUlRYcPHy5QDe3bt9ecOXN08eJFvfXWW3JwcFD37t0lXdlLnpKSYg2o2dLT03XrrbdKktq2bavz589r586d2rJli3Xvf3R0tCRpw4YNioqKsq67Y8cOTZw4Ubt379bZs2eVlZUl6Uq4bdSokbVfixYtrP/+888/lZ6erlatWlnbKlasqPr16193fNWrV7cGfkkKDg5WVlaW4uPjVb58ef3555+KiIiwOQ//8uXL8vT0tNnOv+u5lqioKOte9mz/fv3sGq4ex759+3LdXmRkpAYNGqSPP/5YoaGh6tGjh2rXri1J2rdvnx544AGb/nfeeaemT5+uzMxM7du3Tw4ODgoKCrIub9CgQY7TBy5cuCBvb2+b7Vy6dEl//vlnvsZ8Iwj9AAAAAPLFYrH850PsS6P+/fvrn3/+0YwZM1SjRg05OzsrODhY6enpBdqOu7u79dD7Dz74QM2aNdP777+viIgI63n53333XY7gmr1X2MvLS82aNdP69esVGxurjh076q677lKfPn30+++/68CBA9Y9/RcvXlRYWJjCwsK0aNEi+fj46PDhwwoLC8tRd/Z58EUpe3zvvvuuzQ8KkmRvb/uDTn7rqVSpkvX9LAwTJ07Uww8/rO+++04rV67UhAkTtHjxYj344IOFsv0LFy6oSpUqWr9+fY5lRXnrQC7kBwAAAMD0PDw85O/vrx9//NGm/ccff7Tu9c4+hz8zMzNHn+HDh6tLly7WC7mdPn36P9VjZ2encePG6YUXXtClS5fUqFEjOTs76/Dhw6pTp47NIyAgwLpeSEiI1q1bp40bN6pdu3aqWLGi6tWrp1dffVVVqlRRvXr1JEn79+/XP//8o9dee01t27ZVgwYNcpxfnpvatWvL0dFR27Zts7adPXs2X7e2O3z4sI4fP259vnXrVtnZ2al+/fqqXLmy/P399ddff+UYX/YFFIvC1q1brf/OHse/D7m/Wr169TRy5Ej98MMP6tatmxYsWCBJatiwYa5zp169erK3t1eDBg10+fJl7dixw7o8Pj5eSUlJ1ue33XabEhIS5ODgkOM9qFSpUiGNOKey9zMdAAAAgDIpKipKEyZMUO3atdW8eXMtWLBAu3btsl5oztfXV66urlq1apWqVasmFxcXeXp6qm7dutYr4ScnJysqKqpQbvXWo0cPRUVFafbs2Ro9erRGjx6tkSNHKisrS23atNG5c+f0448/ysPDw3rOe7t27TRz5kz5+PioQYMG1r7vvvuuevToYd129erV5eTkpJkzZ+qJJ57Qnj179NJLL123pnLlyikiIkJRUVHy9vaWr6+vnn/+ednZXX9/sYuLi/r3768pU6YoOTlZw4cPV8+ePa3XR5g0aZKGDx8uT09Pde7cWWlpafr555919uxZRUZGFvj9O3/+vBISEmza3Nzc5OHhYX0+efJkeXt7q3Llynr++edVqVIlhYeH59jWpUuXFBUVpYceekiBgYE6evSofvrpJ+vpF6NGjdLtt9+ul156Sb169VJsbKxmzZplvftA/fr11blzZz3++OOaM2eOHBwc9Mwzz9jMk9DQUAUHBys8PFxvvPGG6tWrp+PHj+u7777Tgw8+mO/TGgqKPf0AAAAAyoThw4crMjJSo0aNUtOmTbVq1Sp9/fXX1gu2OTg46O2339a8efPk7+9vPYf7/fff19mzZ3Xbbbfp0Ucf1fDhw+Xr6/uf63FwcNCwYcP0xhtv6OLFi3rppZf04osvKjo6Wg0bNlTnzp313Xff2ewJb9u2rbKysmwu2NemTRtlZmZabzEoST4+Plq4cKGWLl2qRo0a6bXXXrO53d+1vPnmm2rbtq3uv/9+hYaGqk2bNjbnquelTp066tatm7p06aJOnTrplltusbkl36BBg/Tee+9pwYIFatq0qUJCQrRw4cIb3tM/fvx4ValSxebx7LPP2vR57bXXNGLECAUFBSkhIUHffPON9YiOf7O3t9c///yjfv36qV69eurZs6fuueceTZo0SdKVvfSfffaZFi9erCZNmmj8+PGaPHmyzTUFFixYIH9/f4WEhKhbt24aMmSIzTyxWCxasWKF7rrrLg0cOFD16tVT7969dejQIVWuXPmG3oP8sBj5veEl8pScnCxPT0+dO3fO5lclmFtGRoZWrFihLl265HrLD6C4MUdRGjBPUdKV5Tmampqqv//+W4GBgf/5tmkoOllZWUpOTpaHh0e+9sYXlYkTJ2r58uXatWtXsdXwb+vXr1f79u119uzZIj1fvqhd63uY3xzKnn4AAAAAAEyK0A8AAAAAgEkR+gEAAAAA/8nEiRNLzKH90pULHhqGUaoP7S8shH4AAAAAAEyK0A8AAAAgT1z3Gyg+hfH9I/QDAAAAyCH7bgUpKSnFXAlQdmV///7L3UMcCqsYAAAAAOZhb28vLy8vnTx5UpLk5uYmi8VSzFXhallZWUpPT1dqamqx3rIPhcswDKWkpOjkyZPy8vKSvb39DW+L0A8AAAAgV35+fpJkDf4oeQzD0KVLl+Tq6sqPMibk5eVl/R7eKEI/AAAAgFxZLBZVqVJFvr6+ysjIKO5ykIuMjAxt3LhRd9111386BBwlj6Oj43/aw5+N0A8AAADgmuzt7QslfKDw2dvb6/Lly3JxcSH0I1ec9AEAAAAAgEkR+gEAAAAAMClCPwAAAAAAJkXoBwAAAADApAj9AAAAAACYFKEfAAAAAACTIvQDAAAAAGBShH4AAAAAAEyK0A8AAAAAgEkR+gEAAAAAMClCPwAAAAAAJkXoBwAAAADApAj9AAAAAACYFKEfAAAAAACTIvQDAAAAAGBShH4AAAAAAEyK0A8AAAAAgEkR+gEAAAAAMClCPwAAAAAAJkXoBwAAAADApAj9AAAAAACYFKEfAAAAAACTIvQDAAAAAGBShH4AAAAAAEyq1IX+2bNnq2bNmnJxcVGrVq20ffv2a/ZfunSpGjRoIBcXFzVt2lQrVqzIs+8TTzwhi8Wi6dOnF3LVAAAAAADcfKUq9C9ZskSRkZGaMGGC4uLi1KxZM4WFhenkyZO59t+yZYv69OmjiIgI7dy5U+Hh4QoPD9eePXty9P3yyy+1detW+fv7F/UwAAAAAAC4KUpV6J82bZoGDx6sgQMHqlGjRpo7d67c3Nz0wQcf5Np/xowZ6ty5s6KiotSwYUO99NJLuu222zRr1iybfseOHdPTTz+tRYsWydHR8WYMBQAAAACAIudQ3AXkV3p6unbs2KGxY8da2+zs7BQaGqrY2Nhc14mNjVVkZKRNW1hYmJYvX259npWVpUcffVRRUVFq3LhxvmpJS0tTWlqa9XlycrIkKSMjQxkZGfkdEkq57M+azxwlFXMUpQHzFCUdcxQlHXO07MrvZ15qQv/p06eVmZmpypUr27RXrlxZ+/fvz3WdhISEXPsnJCRYn7/++utycHDQ8OHD811LdHS0Jk2alKP9hx9+kJubW763A3OIiYkp7hKAa2KOojRgnqKkY46ipGOOlj0pKSn56ldqQn9R2LFjh2bMmKG4uDhZLJZ8rzd27FibIwiSk5MVEBCgTp06ycPDoyhKRQmUkZGhmJgYdezYkdNCUCIxR1EaME9R0jFHUdIxR8uu7CPOr6fUhP5KlSrJ3t5eiYmJNu2JiYny8/PLdR0/P79r9t+0aZNOnjyp6tWrW5dnZmZq1KhRmj59ug4ePJjrdp2dneXs7Jyj3dHRkS9aGcTnjpKOOYrSgHmKko45ipKOOVr25PfzLjUX8nNyclJQUJDWrFljbcvKytKaNWsUHByc6zrBwcE2/aUrh71k93/00Uf1yy+/aNeuXdaHv7+/oqKi9P333xfdYAAAAAAAuAlKzZ5+SYqMjFT//v3VokULtWzZUtOnT9fFixc1cOBASVK/fv1UtWpVRUdHS5JGjBihkJAQTZ06Vffee68WL16sn3/+WfPnz5ckeXt7y9vb2+Y1HB0d5efnp/r169/cwQEAAAAAUMhKVejv1auXTp06pfHjxyshIUHNmzfXqlWrrBfrO3z4sOzs/u/ghdatW+vTTz/VCy+8oHHjxqlu3bpavny5mjRpUlxDAAAAAADgpilVoV+Shg0bpmHDhuW6bP369TnaevTooR49euR7+3mdxw8AAAAAQGlTas7pBwAAAAAABUPoBwAAAADApAj9AAAAAACYFKEfAAAAAACTIvQDAAAAAGBShH4AAAAAAEyK0A8AAAAAgEkR+gEAAAAAMClCPwAAAAAAJkXoBwAAAADApAj9AAAAAACYFKEfAAAAAACTIvQDAAAAAGBShH4AAAAAAEyK0A8AAAAAgEkR+gEAAAAAMClCPwAAAAAAJkXoBwAAAADApAj9AAAAAACYFKEfAAAAAACTIvQDAAAAAGBShH4AAAAAAEyK0A8AAAAAgEkR+gEAAAAAMClCPwAAAAAAJkXoBwAAAADApAj9AAAAAACYFKEfAAAAAACTIvQDAAAAAGBShH4AAAAAAEyK0A8AAAAAgEkR+gEAAAAAMClCPwAAAAAAJkXoBwAAAADApAj9AAAAAACYFKEfAAAAAACTIvQDAAAAAGBShH4AAAAAAEyK0A8AAAAAgEkR+gEAAAAAMClCPwAAAAAAJkXoBwAAAADApAj9AAAAAACYFKEfAAAAAACTIvQDAAAAAGBShH4AAAAAAEyK0A8AAAAAgEkR+gEAAAAAMClCPwAAAAAAJkXoBwAAAADApAj9AAAAAACYFKEfAAAAAACTIvQDAAAAAGBShH4AAAAAAEyK0A8AAAAAgEkR+gEAAAAAMClCPwAAAAAAJkXoBwAAAADApAj9AAAAAACYFKEfAAAAAACTIvQDAAAAAGBShH4AAAAAAEyK0A8AAAAAgEkR+gEAAAAAMClCPwAAAAAAJkXoBwAAAADApAj9AAAAAACYFKEfAAAAAACTIvQDAAAAAGBShH4AAAAAAEyK0A8AAAAAgEkR+gEAAAAAMClCPwAAAAAAJlXqQv/s2bNVs2ZNubi4qFWrVtq+ffs1+y9dulQNGjSQi4uLmjZtqhUrVliXZWRk6LnnnlPTpk3l7u4uf39/9evXT8ePHy/qYQAAAAAAUORKVehfsmSJIiMjNWHCBMXFxalZs2YKCwvTyZMnc+2/ZcsW9enTRxEREdq5c6fCw8MVHh6uPXv2SJJSUlIUFxenF198UXFxcfriiy8UHx+vrl273sxhAQAAAABQJEpV6J82bZoGDx6sgQMHqlGjRpo7d67c3Nz0wQcf5Np/xowZ6ty5s6KiotSwYUO99NJLuu222zRr1ixJkqenp2JiYtSzZ0/Vr19fd9xxh2bNmqUdO3bo8OHDN3NoAAAAAAAUOofiLiC/0tPTtWPHDo0dO9baZmdnp9DQUMXGxua6TmxsrCIjI23awsLCtHz58jxf59y5c7JYLPLy8sqzT1pamtLS0qzPk5OTJV05XSAjIyMfo4EZZH/WfOYoqZijKA2YpyjpmKMo6ZijZVd+P/NSE/pPnz6tzMxMVa5c2aa9cuXK2r9/f67rJCQk5No/ISEh1/6pqal67rnn1KdPH3l4eORZS3R0tCZNmpSj/YcffpCbm9v1hgKTiYmJKe4SgGtijqI0YJ6ipGOOoqRjjpY9KSkp+epXakJ/UcvIyFDPnj1lGIbmzJlzzb5jx461OYIgOTlZAQEB6tSp0zV/LIC5ZGRkKCYmRh07dpSjo2NxlwPkwBxFacA8RUnHHEVJxxwtu7KPOL+eUhP6K1WqJHt7eyUmJtq0JyYmys/PL9d1/Pz88tU/O/AfOnRIa9euvW5wd3Z2lrOzc452R0dHvmhlEJ87SjrmKEoD5ilKOuYoSjrmaNmT38+71FzIz8nJSUFBQVqzZo21LSsrS2vWrFFwcHCu6wQHB9v0l64c9vLv/tmB/8CBA1q9erW8vb2LZgAAAAAAANxkpWZPvyRFRkaqf//+atGihVq2bKnp06fr4sWLGjhwoCSpX79+qlq1qqKjoyVJI0aMUEhIiKZOnap7771Xixcv1s8//6z58+dLuhL4H3roIcXFxenbb79VZmam9Xz/ihUrysnJqXgGCgAAAABAIShVob9Xr146deqUxo8fr4SEBDVv3lyrVq2yXqzv8OHDsrP7v4MXWrdurU8//VQvvPCCxo0bp7p162r58uVq0qSJJOnYsWP6+uuvJUnNmze3ea1169apXbt2N2VcAAAAAAAUhVIV+iVp2LBhGjZsWK7L1q9fn6OtR48e6tGjR679a9asKcMwCrM8AAAAAABKjFJzTj8AAAAAACgYQj8AAAAAACZF6AcAAAAAwKQI/QAAAAAAmBShHwAAAAAAkyL0AwAAAABgUoR+AAAAAABMitAPAAAAAIBJEfoBAAAAADApQj8AAAAAACZF6AcAAAAAwKQI/QAAAAAAmBShHwAAAAAAkyL0AwAAAABgUoR+AAAAAABMitAPAAAAAIBJEfoBAAAAADApQj8AAAAAACZF6AcAAAAAwKQI/QAAAAAAmBShHwAAAAAAkyL0AwAAAABgUoR+AAAAAABMitAPAAAAAIBJEfoBAAAAADApQj8AAAAAACZF6AcAAAAAwKQI/QAAAAAAmBShHwAAAAAAkyL0AwAAAABgUoR+AAAAAABMitAPAAAAAIBJEfoBAAAAADApQj8AAAAAACZF6AcAAAAAwKQc8tMpMjIy3xucNm3aDRcDAAAAAAAKT75C/86dO22ex8XF6fLly6pfv74k6ffff5e9vb2CgoIKv0IAAAAAAHBD8hX6161bZ/33tGnTVL58eX344YeqUKGCJOns2bMaOHCg2rZtWzRVAgAAAACAAivwOf1Tp05VdHS0NfBLUoUKFfTyyy9r6tSphVocAAAAAAC4cQUO/cnJyTp16lSO9lOnTun8+fOFUhQAAAAAAPjvChz6H3zwQQ0cOFBffPGFjh49qqNHj+rzzz9XRESEunXrVhQ1AgAAAACAG5Cvc/r/be7cuRo9erQefvhhZWRkXNmIg4MiIiL05ptvFnqBAAAAAADgxhQo9GdmZurnn3/WK6+8ojfffFN//vmnJKl27dpyd3cvkgIBAAAAAMCNKVDot7e3V6dOnbRv3z4FBgbqlltuKaq6AAAAAADAf1Tgc/qbNGmiv/76qyhqAQAAAAAAhajAof/ll1/W6NGj9e233+rEiRNKTk62eQAAAAAAgJKhwBfy69KliySpa9euslgs1nbDMGSxWJSZmVl41QEAAAAAgBtW4NC/bt26oqgDAAAAAAAUsgKH/pCQkKKoAwAAAAAAFLICh/5sKSkpOnz4sNLT023auaI/AAAAAAAlQ4FD/6lTpzRw4ECtXLky1+Wc0w8AAAAAQMlQ4Kv3P/PMM0pKStK2bdvk6uqqVatW6cMPP1TdunX19ddfF0WNAAAAAADgBhR4T//atWv11VdfqUWLFrKzs1ONGjXUsWNHeXh4KDo6Wvfee29R1AkAAAAAAAqowHv6L168KF9fX0lShQoVdOrUKUlS06ZNFRcXV7jVAQAAAACAG1bg0F+/fn3Fx8dLkpo1a6Z58+bp2LFjmjt3rqpUqVLoBQIAAAAAgBtT4MP7R4wYoRMnTkiSJkyYoM6dO2vRokVycnLSwoULC7s+AAAAAABwgwoc+h955BHrv4OCgnTo0CHt379f1atXV6VKlQq1OAAAAAAAcOMKfHj/X3/9ZfPczc1Nt912G4EfAAAAAIASpsB7+uvUqaNq1aopJCRE7dq1U0hIiOrUqVMUtQEAAAAAgP+gwHv6jxw5oujoaLm6uuqNN95QvXr1VK1aNfXt21fvvfdeUdQIAAAAAABuQIFDf9WqVdW3b1/Nnz9f8fHxio+PV2hoqD777DM9/vjjRVEjAAAAAAC4AQU+vD8lJUWbN2/W+vXrtX79eu3cuVMNGjTQsGHD1K5duyIoEQAAAAAA3IgCh34vLy9VqFBBffv21ZgxY9S2bVtVqFChKGoDAAAAAAD/QYFDf5cuXbR582YtXrxYCQkJSkhIULt27VSvXr2iqA8AAAAAANygAp/Tv3z5cp0+fVqrVq1ScHCwfvjhB7Vt29Z6rj8AAAAAACgZCrynP1vTpk11+fJlpaenKzU1Vd9//72WLFmiRYsWFWZ9AAAAAADgBhV4T/+0adPUtWtXeXt7q1WrVvrf//6nevXq6fPPP9epU6eKokYAAAAAAHADCryn/3//+59CQkI0ZMgQtW3bVp6enkVRFwAAAAAA+I8KHPp/+umnoqgDAAAAAAAUsgIf3i9JmzZt0iOPPKLg4GAdO3ZMkvTxxx9r8+bNhVocAAAAAAC4cQUO/Z9//rnCwsLk6uqqnTt3Ki0tTZJ07tw5vfrqq4VeIAAAAAAAuDEFDv0vv/yy5s6dq3fffVeOjo7W9jvvvFNxcXGFWhwAAAAAALhxBQ798fHxuuuuu3K0e3p6KikpqTBqAgAAAAAAhaDAod/Pz09//PFHjvbNmzerVq1ahVLUtcyePVs1a9aUi4uLWrVqpe3bt1+z/9KlS9WgQQO5uLioadOmWrFihc1ywzA0fvx4ValSRa6urgoNDdWBAweKcggAAAAAANwUBQ79gwcP1ogRI7Rt2zZZLBYdP35cixYt0ujRo/Xkk08WRY1WS5YsUWRkpCZMmKC4uDg1a9ZMYWFhOnnyZK79t2zZoj59+igiIkI7d+5UeHi4wsPDtWfPHmufN954Q2+//bbmzp2rbdu2yd3dXWFhYUpNTS3SsQAAAAAAUNQKHPrHjBmjhx9+WB06dNCFCxd01113adCgQXr88cf19NNPF0WNVtOmTdPgwYM1cOBANWrUSHPnzpWbm5s++OCDXPvPmDFDnTt3VlRUlBo2bKiXXnpJt912m2bNmiXpyl7+6dOn64UXXtADDzygW265RR999JGOHz+u5cuXF+lYAAAAAAAoag4FXcFisej5559XVFSU/vjjD124cEGNGjVSuXLldOnSJbm6uhZFnUpPT9eOHTs0duxYa5udnZ1CQ0MVGxub6zqxsbGKjIy0aQsLC7MG+r///lsJCQkKDQ21Lvf09FSrVq0UGxur3r1757rdtLQ0610LJCk5OVmSlJGRoYyMjBsaH0qf7M+azxwlFXMUpQHzFCUdcxQlHXO07MrvZ17g0J/NyclJjRo1knQlBE+bNk1vvPGGEhISbnST13T69GllZmaqcuXKNu2VK1fW/v37c10nISEh1/7ZNWb/91p9chMdHa1JkyblaP/hhx/k5uZ2/cHAVGJiYoq7BOCamKMoDZinKOmYoyjpmKNlT0pKSr765Tv0p6WlaeLEiYqJiZGTk5OeffZZhYeHa8GCBXr++edlb2+vkSNH3nDBpcnYsWNtjiBITk5WQECAOnXqJA8Pj2KsDDdTRkaGYmJi1LFjR5vbVwIlBXMUpQHzFCUdcxQlHXO07Mo+4vx68h36x48fr3nz5ik0NFRbtmxRjx49NHDgQG3dulXTpk1Tjx49ZG9vf8MFX0+lSpVkb2+vxMREm/bExET5+fnluo6fn981+2f/NzExUVWqVLHp07x58zxrcXZ2lrOzc452R0dHvmhlEJ87SjrmKEoD5ilKOuYoSjrmaNmT38873xfyW7p0qT766CMtW7ZMP/zwgzIzM3X58mXt3r1bvXv3LtLAL105nSAoKEhr1qyxtmVlZWnNmjUKDg7OdZ3g4GCb/tKVw16y+wcGBsrPz8+mT3JysrZt25bnNgEAAAAAKC3yvaf/6NGjCgoKkiQ1adJEzs7OGjlypCwWS5EVd7XIyEj1799fLVq0UMuWLTV9+nRdvHhRAwcOlCT169dPVatWVXR0tCRpxIgRCgkJ0dSpU3Xvvfdq8eLF+vnnnzV//nxJVy5K+Mwzz+jll19W3bp1FRgYqBdffFH+/v4KDw+/aeMCAAAAAKAo5Dv0Z2ZmysnJ6f9WdHBQuXLliqSovPTq1UunTp3S+PHjlZCQoObNm2vVqlXWC/EdPnxYdnb/d/BC69at9emnn+qFF17QuHHjVLduXS1fvlxNmjSx9nn22Wd18eJFDRkyRElJSWrTpo1WrVolFxeXmzo2AAAAAAAKW75Dv2EYGjBggPVc9tTUVD3xxBNyd3e36ffFF18UboVXGTZsmIYNG5brsvXr1+do69Gjh3r06JHn9iwWiyZPnqzJkycXVokAAAAAAJQI+Q79/fv3t3n+yCOPFHoxAAAAAACg8OQ79C9YsKAo6wAAAAAAAIUs31fvBwAAAAAApQuhHwAAAAAAkyL0AwAAAABgUoR+AAAAAABMitAPAAAAAIBJ5evq/V9//XW+N9i1a9cbLgYAAAAAABSefIX+8PDwfG3MYrEoMzPzv9QDAAAAAAAKSb5Cf1ZWVlHXAQAAAAAAChnn9AMAAAAAYFL52tN/tYsXL2rDhg06fPiw0tPTbZYNHz68UAoDAAAAAAD/TYFD/86dO9WlSxelpKTo4sWLqlixok6fPi03Nzf5+voS+gEAAAAAKCEKfHj/yJEjdf/99+vs2bNydXXV1q1bdejQIQUFBWnKlClFUSMAAAAAALgBBQ79u3bt0qhRo2RnZyd7e3ulpaUpICBAb7zxhsaNG1cUNQIAAAAAgBtQ4NDv6OgoO7srq/n6+urw4cOSJE9PTx05cqRwqwMAAAAAADeswOf033rrrfrpp59Ut25dhYSEaPz48Tp9+rQ+/vhjNWnSpChqBAAAAAAAN6DAe/pfffVVValSRZL0yiuvqEKFCnryySd16tQpzZs3r9ALBAAAAAAAN6bAe/pbtGhh/bevr69WrVpVqAUBAAAAAIDCUeA9/XfffbeSkpJytCcnJ+vuu+8ujJoAAAAAAEAhKHDoX79+vdLT03O0p6amatOmTYVSFAAAAAAA+O/yfXj/L7/8Yv333r17lZCQYH2emZmpVatWqWrVqoVbHQAAAAAAuGH5Dv3NmzeXxWKRxWLJ9TB+V1dXzZw5s1CLAwAAAAAANy7fof/vv/+WYRiqVauWtm/fLh8fH+syJycn+fr6yt7evkiKBAAAAAAABZfv0F+jRg1JUlZWVpEVAwAAAAAACk+Bb9knSX/++aemT5+uffv2SZIaNWqkESNGqHbt2oVaHAAAAAAAuHEFvnr/999/r0aNGmn79u265ZZbdMstt2jbtm1q3LixYmJiiqJGAAAAAABwAwq8p3/MmDEaOXKkXnvttRztzz33nDp27FhoxQEAAAAAgBtX4D39+/btU0RERI72xx57THv37i2UogAAAAAAwH9X4NDv4+OjXbt25WjftWuXfH19C6MmAAAAAABQCPJ9eP/kyZM1evRoDR48WEOGDNFff/2l1q1bS5J+/PFHvf7664qMjCyyQgEAAAAAQMHkO/RPmjRJTzzxhF588UWVL19eU6dO1dixYyVJ/v7+mjhxooYPH15khQIAAAAAgILJd+g3DEOSZLFYNHLkSI0cOVLnz5+XJJUvX75oqgMAAAAAADesQFfvt1gsNs8J+wAAAAAAlFwFCv316tXLEfyvdubMmf9UEAAAAAAAKBwFCv2TJk2Sp6dnUdUCAAAAAAAKUYFCf+/evbktHwAAAAAApYRdfjte77B+AAAAAABQsuQ79GdfvR8AAAAAAJQO+T68PysrqyjrAAAAAAAAhSzfe/oBAAAAAEDpQugHAAAAAMCkCP0AAAAAAJgUoR8AAAAAAJMi9AMAAAAAYFKEfgAAAAAATIrQDwAAAACASRH6AQAAAAAwKUI/AAAAAAAmRegHAAAAAMCkCP0AAAAAAJgUoR8AAAAAAJMi9AMAAAAAYFKEfgAAAAAATIrQDwAAAACASRH6AQAAAAAwKUI/AAAAAAAmRegHAAAAAMCkCP0AAAAAAJgUoR8AAAAAAJMi9AMAAAAAYFKEfgAAAAAATIrQDwAAAACASRH6AQAAAAAwKUI/AAAAAAAmRegHAAAAAMCkCP0AAAAAAJgUoR8AAAAAAJMi9AMAAAAAYFKEfgAAAAAATIrQDwAAAACASRH6AQAAAAAwKUI/AAAAAAAmVWpC/5kzZ9S3b195eHjIy8tLERERunDhwjXXSU1N1dChQ+Xt7a1y5cqpe/fuSkxMtC7fvXu3+vTpo4CAALm6uqphw4aaMWNGUQ8FAAAAAICbotSE/r59++q3335TTEyMvv32W23cuFFDhgy55jojR47UN998o6VLl2rDhg06fvy4unXrZl2+Y8cO+fr66pNPPtFvv/2m559/XmPHjtWsWbOKejgAAAAAABQ5h+IuID/27dunVatW6aefflKLFi0kSTNnzlSXLl00ZcoU+fv751jn3Llzev/99/Xpp5/q7rvvliQtWLBADRs21NatW3XHHXfoscces1mnVq1aio2N1RdffKFhw4YV/cAAAAAAAChCpSL0x8bGysvLyxr4JSk0NFR2dnbatm2bHnzwwRzr7NixQxkZGQoNDbW2NWjQQNWrV1dsbKzuuOOOXF/r3Llzqlix4jXrSUtLU1pamvV5cnKyJCkjI0MZGRkFGhtKr+zPms8cJRVzFKUB8xQlHXMUJR1ztOzK72deKkJ/QkKCfH19bdocHBxUsWJFJSQk5LmOk5OTvLy8bNorV66c5zpbtmzRkiVL9N13312znujoaE2aNClH+w8//CA3N7drrgvziYmJKe4SgGtijqI0YJ6ipGOOoqRjjpY9KSkp+epXrKF/zJgxev3116/ZZ9++fTellj179uiBBx7QhAkT1KlTp2v2HTt2rCIjI63Pk5OTFRAQoE6dOsnDw6OoS0UJkZGRoZiYGHXs2FGOjo7FXQ6QA3MUpQHzFCUdcxQlHXO07Mo+4vx6ijX0jxo1SgMGDLhmn1q1asnPz08nT560ab98+bLOnDkjPz+/XNfz8/NTenq6kpKSbPb2JyYm5lhn79696tChg4YMGaIXXnjhunU7OzvL2dk5R7ujoyNftDKIzx0lHXMUpQHzFCUdcxQlHXO07Mnv512sod/Hx0c+Pj7X7RccHKykpCTt2LFDQUFBkqS1a9cqKytLrVq1ynWdoKAgOTo6as2aNerevbskKT4+XocPH1ZwcLC132+//aa7775b/fv31yuvvFIIowIAAAAAoGQoFbfsa9iwoTp37qzBgwdr+/bt+vHHHzVs2DD17t3beuX+Y8eOqUGDBtq+fbskydPTUxEREYqMjNS6deu0Y8cODRw4UMHBwdaL+O3Zs0ft27dXp06dFBkZqYSEBCUkJOjUqVPFNlYAAAAAAApLqbiQnyQtWrRIw4YNU4cOHWRnZ6fu3bvr7bffti7PyMhQfHy8zcUM3nrrLWvftLQ0hYWF6Z133rEuX7ZsmU6dOqVPPvlEn3zyibW9Ro0aOnjw4E0ZFwAAAAAARaXUhP6KFSvq008/zXN5zZo1ZRiGTZuLi4tmz56t2bNn57rOxIkTNXHixMIsEwAAAACAEqNUHN4PAAAAAAAKjtAPAAAAAIBJEfoBAAAAADApQj8AAAAAACZF6AcAAAAAwKQI/QAAAAAAmBShHwAAAAAAkyL0AwAAAABgUoR+AAAAAABMitAPAAAAAIBJEfoBAAAAADApQj8AAAAAACZF6AcAAAAAwKQI/QAAAAAAmBShHwAAAAAAkyL0AwAAAABgUoR+AAAAAABMitAPAAAAAIBJEfoBAAAAADApQj8AAAAAACZF6AcAAAAAwKQI/QAAAAAAmBShHwAAAAAAkyL0AwAAAABgUoR+AAAAAABMitAPAAAAAIBJEfoBAAAAADApQj8AAAAAACZF6AcAAAAAwKQI/QAAAAAAmBShHwAAAAAAkyL0AwAAAABgUoR+AAAAAABMitAPAAAAAIBJEfoBAAAAADApQj8AAAAAACZF6AcAAAAAwKQI/QAAAAAAmBShHwAAAAAAkyL0AwAAAABgUoR+AAAAAABMitAPAAAAAIBJEfoBAAAAADApQj8AAAAAACZF6AcAAAAAwKQI/QAAAAAAmBShHwAAAAAAkyL0AwAAAABgUoR+AAAAAABMitAPAAAAAIBJEfoBAAAAADApQj8AAAAAACZF6AcAAAAAwKQI/QAAAAAAmBShHwAAAAAAkyL0AwAAAABgUoR+AAAAAABMitAPAAAAAIBJEfoBAAAAADApQj8AAAAAACZF6AcAAAAAwKQI/QAAAAAAmBShHwAAAAAAkyL0AwAAAABgUoR+AAAAAABMitAPAAAAAIBJEfoBAAAAADApQj8AAAAAACZF6AcAAAAAwKQI/QAAAAAAmBShHwAAAAAAkyL0AwAAAABgUoR+AAAAAABMqtSE/jNnzqhv377y8PCQl5eXIiIidOHChWuuk5qaqqFDh8rb21vlypVT9+7dlZiYmGvff/75R9WqVZPFYlFSUlIRjAAAAAAAgJur1IT+vn376rffflNMTIy+/fZbbdy4UUOGDLnmOiNHjtQ333yjpUuXasOGDTp+/Li6deuWa9+IiAjdcsstRVE6AAAAAADFolSE/n379mnVqlV677331KpVK7Vp00YzZ87U4sWLdfz48VzXOXfunN5//31NmzZNd999t4KCgrRgwQJt2bJFW7dutek7Z84cJSUlafTo0TdjOAAAAAAA3BQOxV1AfsTGxsrLy0stWrSwtoWGhsrOzk7btm3Tgw8+mGOdHTt2KCMjQ6Ghoda2Bg0aqHr16oqNjdUdd9whSdq7d68mT56sbdu26a+//spXPWlpaUpLS7M+T05OliRlZGQoIyPjhsaI0if7s+YzR0nFHEVpwDxFScccRUnHHC278vuZl4rQn5CQIF9fX5s2BwcHVaxYUQkJCXmu4+TkJC8vL5v2ypUrW9dJS0tTnz599Oabb6p69er5Dv3R0dGaNGlSjvYffvhBbm5u+doGzCMmJqa4SwCuiTmK0oB5ipKOOYqSjjla9qSkpOSrX7GG/jFjxuj111+/Zp99+/YV2euPHTtWDRs21COPPFLg9SIjI63Pk5OTFRAQoE6dOsnDw6Owy0QJlZGRoZiYGHXs2FGOjo7FXQ6QA3MUpQHzFCUdcxQlHXO07Mo+4vx6ijX0jxo1SgMGDLhmn1q1asnPz08nT560ab98+bLOnDkjPz+/XNfz8/NTenq6kpKSbPb2JyYmWtdZu3atfv31Vy1btkySZBiGJKlSpUp6/vnnc92bL0nOzs5ydnbO0e7o6MgXrQzic0dJxxxFacA8RUnHHEVJxxwte/L7eRdr6Pfx8ZGPj891+wUHByspKUk7duxQUFCQpCuBPSsrS61atcp1naCgIDk6OmrNmjXq3r27JCk+Pl6HDx9WcHCwJOnzzz/XpUuXrOv89NNPeuyxx7Rp0ybVrl37vw4PAAAAAIBiVSrO6W/YsKE6d+6swYMHa+7cucrIyNCwYcPUu3dv+fv7S5KOHTumDh066KOPPlLLli3l6empiIgIRUZGqmLFivLw8NDTTz+t4OBg60X8rg72p0+ftr7e1dcCAAAAAACgtCkVoV+SFi1apGHDhqlDhw6ys7NT9+7d9fbbb1uXZ2RkKD4+3uZiBm+99Za1b1pamsLCwvTOO+8UR/kAAAAAANx0pSb0V6xYUZ9++mmey2vWrGk9Jz+bi4uLZs+erdmzZ+frNdq1a5djGwAAAAAAlFZ2xV0AAAAAAAAoGoR+AAAAAABMitAPAAAAAIBJEfoBAAAAADApQj8AAAAAACZF6AcAAAAAwKQI/QAAAAAAmBShHwAAAAAAkyL0AwAAAABgUoR+AAAAAABMitAPAAAAAIBJEfoBAAAAADApQj8AAAAAACZF6AcAAAAAwKQI/QAAAAAAmBShHwAAAAAAkyL0AwAAAABgUoR+AAAAAABMitAPAAAAAIBJEfoBAAAAADApQj8AAAAAACZF6AcAAAAAwKQI/QAAAAAAmBShHwAAAAAAkyL0AwAAAABgUoR+AAAAAABMitAPAAAAAIBJEfoBAAAAADApQj8AAAAAACZF6AcAAAAAwKQI/QAAAAAAmBShHwAAAAAAkyL0AwAAAABgUoR+AAAAAABMitAPAAAAAIBJEfoBAAAAADApQj8AAAAAACZF6AcAAAAAwKQI/QAAAAAAmBShHwAAAAAAkyL0AwAAAABgUoR+AAAAAABMitAPAAAAAIBJEfoBAAAAADApQj8AAAAAACZF6AcAAAAAwKQI/QAAAAAAmBShHwAAAAAAkyL0AwAAAABgUoR+AAAAAABMitAPAAAAAIBJEfoBAAAAADApQj8AAAAAACZF6AcAAAAAwKQI/QAAAAAAmJRDcRdgBoZhSJKSk5OLuRLcTBkZGUpJSVFycrIcHR2LuxwgB+YoSgPmKUo65ihKOuZo2ZWdP7PzaF4I/YXg/PnzkqSAgIBirgQAAAAAUJacP39enp6eeS63GNf7WQDXlZWVpePHj6t8+fKyWCzFXQ5ukuTkZAUEBOjIkSPy8PAo7nKAHJijKA2YpyjpmKMo6ZijZZdhGDp//rz8/f1lZ5f3mfvs6S8EdnZ2qlatWnGXgWLi4eHBH1iUaMxRlAbMU5R0zFGUdMzRsulae/izcSE/AAAAAABMitAPAAAAAIBJEfqBG+Ts7KwJEybI2dm5uEsBcsUcRWnAPEVJxxxFScccxfVwIT8AAAAAAEyKPf0AAAAAAJgUoR8AAAAAAJMi9AMAAAAAYFKEfgAAAAAATIrQD1zDmTNn1LdvX3l4eMjLy0sRERG6cOHCNddJTU3V0KFD5e3trXLlyql79+5KTEzMte8///yjatWqyWKxKCkpqQhGALMrijm6e/du9enTRwEBAXJ1dVXDhg01Y8aMoh4KTGL27NmqWbOmXFxc1KpVK23fvv2a/ZcuXaoGDRrIxcVFTZs21YoVK2yWG4ah8ePHq0qVKnJ1dVVoaKgOHDhQlEOAyRXmHM3IyNBzzz2npk2byt3dXf7+/urXr5+OHz9e1MOAiRX239F/e+KJJ2SxWDR9+vRCrholGaEfuIa+ffvqt99+U0xMjL799ltt3LhRQ4YMueY6I0eO1DfffKOlS5dqw4YNOn78uLp165Zr34iICN1yyy1FUTrKiKKYozt27JCvr68++eQT/fbbb3r++ec1duxYzZo1q6iHg1JuyZIlioyM1IQJExQXF6dmzZopLCxMJ0+ezLX/li1b1KdPH0VERGjnzp0KDw9XeHi49uzZY+3zxhtv6O2339bcuXO1bds2ubu7KywsTKmpqTdrWDCRwp6jKSkpiouL04svvqi4uDh98cUXio+PV9euXW/msGAiRfF3NNuXX36prVu3yt/fv6iHgZLGAJCrvXv3GpKMn376ydq2cuVKw2KxGMeOHct1naSkJMPR0dFYunSptW3fvn2GJCM2Ntam7zvvvGOEhIQYa9asMSQZZ8+eLZJxwLyKeo7+21NPPWW0b9++8IqHKbVs2dIYOnSo9XlmZqbh7+9vREdH59q/Z8+exr333mvT1qpVK+Pxxx83DMMwsrKyDD8/P+PNN9+0Lk9KSjKcnZ2N//3vf0UwAphdYc/R3Gzfvt2QZBw6dKhwikaZUlRz9OjRo0bVqlWNPXv2GDVq1DDeeuutQq8dJRd7+oE8xMbGysvLSy1atLC2hYaGys7OTtu2bct1nR07digjI0OhoaHWtgYNGqh69eqKjY21tu3du1eTJ0/WRx99JDs7voa4MUU5R6927tw5VaxYsfCKh+mkp6drx44dNnPLzs5OoaGhec6t2NhYm/6SFBYWZu3/999/KyEhwaaPp6enWrVqdc35CuSmKOZobs6dOyeLxSIvL69CqRtlR1HN0aysLD366KOKiopS48aNi6Z4lGikDSAPCQkJ8vX1tWlzcHBQxYoVlZCQkOc6Tk5OOf6HvnLlytZ10tLS1KdPH7355puqXr16kdSOsqGo5ujVtmzZoiVLllz3tAGUbadPn1ZmZqYqV65s036tuZWQkHDN/tn/Lcg2gbwUxRy9Wmpqqp577jn16dNHHh4ehVM4yoyimqOvv/66HBwcNHz48MIvGqUCoR9lzpgxY2SxWK752L9/f5G9/tixY9WwYUM98sgjRfYaKN2Ke47+2549e/TAAw9owoQJ6tSp0015TQAojTIyMtSzZ08ZhqE5c+YUdzmApCtH+M2YMUMLFy6UxWIp7nJQTByKuwDgZhs1apQGDBhwzT61atWSn59fjoumXL58WWfOnJGfn1+u6/n5+Sk9PV1JSUk2e1ITExOt66xdu1a//vqrli1bJunKlaklqVKlSnr++ec1adKkGxwZzKK452i2vXv3qkOHDhoyZIheeOGFGxoLyo5KlSrJ3t4+x91Kcptb2fz8/K7ZP/u/iYmJqlKlik2f5s2bF2L1KAuKYo5myw78hw4d0tq1a9nLjxtSFHN006ZNOnnypM3RpZmZmRo1apSmT5+ugwcPFu4gUCKxpx9ljo+Pjxo0aHDNh5OTk4KDg5WUlKQdO3ZY1127dq2ysrLUqlWrXLcdFBQkR0dHrVmzxtoWHx+vw4cPKzg4WJL0+eefa/fu3dq1a5d27dql9957T9KVP8pDhw4twpGjtCjuOSpJv/32m9q3b6/+/fvrlVdeKbrBwjScnJwUFBRkM7eysrK0Zs0am7n1b8HBwTb9JSkmJsbaPzAwUH5+fjZ9kpOTtW3btjy3CeSlKOao9H+B/8CBA1q9erW8vb2LZgAwvaKYo48++qh++eUX6//v3LVrl/z9/RUVFaXvv/++6AaDkqW4ryQIlGSdO3c2br31VmPbtm3G5s2bjbp16xp9+vSxLj969KhRv359Y9u2bda2J554wqhevbqxdu1a4+effzaCg4ON4ODgPF9j3bp1XL0fN6wo5uivv/5q+Pj4GI888ohx4sQJ6+PkyZM3dWwofRYvXmw4OzsbCxcuNPbu3WsMGTLE8PLyMhISEgzDMIxHH33UGDNmjLX/jz/+aDg4OBhTpkwx9u3bZ0yYMMFwdHQ0fv31V2uf1157zfDy8jK++uor45dffjEeeOABIzAw0Lh06dJNHx9Kv8Keo+np6UbXrl2NatWqGbt27bL5m5mWllYsY0TpVhR/R6/G1fvLHkI/cA3//POP0adPH6NcuXKGh4eHMXDgQOP8+fPW5X///bchyVi3bp217dKlS8ZTTz1lVKhQwXBzczMefPBB48SJE3m+BqEf/0VRzNEJEyYYknI8atSocRNHhtJq5syZRvXq1Q0nJyejZcuWxtatW63LQkJCjP79+9v0/+yzz4x69eoZTk5ORuPGjY3vvvvOZnlWVpbx4osvGpUrVzacnZ2NDh06GPHx8TdjKDCpwpyj2X9jc3v8++8uUBCF/Xf0aoT+ssdiGP//hGIAAAAAAGAqnNMPAAAAAIBJEfoBAAAAADApQj8AAAAAACZF6AcAAAAAwKQI/QAAAAAAmBShHwAAAAAAkyL0AwAAAABgUoR+AAAAAABMitAPAAAKxcGDB2WxWLRr164ie40BAwYoPDy8yLYPAIDZEPoBAICkK4HaYrHkeHTu3Dlf6wcEBOjEiRNq0qRJEVcKAADyy6G4CwAAACVH586dtWDBAps2Z2fnfK1rb28vPz+/oigLAADcIPb0AwAAK2dnZ/n5+dk8KlSoIEmyWCyaM2eO7rnnHrm6uqpWrVpatmyZdd2rD+8/e/as+vbtKx8fH7m6uqpu3bo2Pyj8+uuvuvvuu+Xq6ipvb28NGTJEFy5csC7PzMxUZGSkvLy85O3trWeffVaGYdjUm5WVpejoaAUGBsrV1VXNmjWzqel6NQAAYHaEfgAAkG8vvviiunfvrt27d6tv377q3bu39u3bl2ffvXv3auXKldq3b5/mzJmjSpUqSZIuXryosLAwVahQQT/99JOWLl2q1atXa9iwYdb1p06dqoULF+qDDz7Q5s2bdebMGX355Zc2rxEdHa2PPvpIc+fO1W+//aaRI0fqkUce0YYNG65bAwAAZYHFuPoncwAAUCYNGDBAn3zyiVxcXGzax40bp3HjxsliseiJJ57QnDlzrMvuuOMO3XbbbXrnnXd08OBBBQYGaufOnWrevLm6du2qSpUq6YMPPsjxWu+++66ee+45HTlyRO7u7pKkFStW6P7779fx48dVuXJl+fv7a+TIkYqKipIkXb58WYGBgQoKCtLy5cuVlpamihUravXq1QoODrZue9CgQUpJSdGnn356zRoAACgLOKcfAABYtW/f3ibUS1LFihWt//53uM5+ntfV+p988kl1795dcXFx6tSpk8LDw9W6dWtJ0r59+9SsWTNr4JekO++8U1lZWYqPj5eLi4tOnDihVq1aWZc7ODioRYsW1kP8//jjD6WkpKhjx442r5uenq5bb731ujUAAFAWEPoBAICVu7u76tSpUyjbuueee3To0CGtWLFCMTEx6tChg4YOHaopU6YUyvazz///7rvvVLVqVZtl2RcfLOoaAAAo6TinHwAA5NvWrVtzPG/YsGGe/X18fNS/f3998sknmj59uubPny9JatiwoXbv3q2LFy9a+/7444+ys7NT/fr15enpqSpVqmjbtm3W5ZcvX9aOHTuszxs1aiRnZ2cdPnxYderUsXkEBARctwYAAMoC9vQDAACrtLQ0JSQk2LQ5ODhYL363dOlStWjRQm3atNGiRYu0fft2vf/++7lua/z48QoKClLjxo2Vlpamb7/91voDQd++fTVhwgT1799fEydO1KlTp/T000/r0UcfVeXKlSVJI0aM0Guvvaa6deuqQYMGmjZtmpKSkqzbL1++vEaPHq2RI0cqKytLbdq00blz5/Tjjz/Kw8ND/fv3v2YNAACUBYR+AABgtWrVKlWpUsWmrX79+tq/f78kadKkSVq8eLGeeuopValSRf/73//UqFGjXLfl5OSksWPH6uDBg3J1dVXbtm21ePFiSZKbm5u+//57jRgxQrfffrvc3NzUvXt3TZs2zbr+qFGjdOLECfXv3192dnZ67LHH9OCDD+rcuXPWPi+99JJ8fHwUHR2tv/76S15eXrrttts0bty469YAAEBZwNX7AQBAvlgsFn355ZcKDw8v7lIAAEA+cU4/AAAAAAAmRegHAAAAAMCkOKcfAADkC2cEAgBQ+rCnHwAAAAAAkyL0AwAAAABgUoR+AAAAAABMitAPAAAAAIBJEfoBAAAAADApQj8AAAAAACZF6AcAAAAAwKQI/QAAAAAAmNT/A5Q1GxD3hMY3AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **可视化**"
      ],
      "metadata": {
        "id": "12ckp5Qhv8bw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop with Video Capturing\n",
        "from google.colab import files\n",
        "files.download('complete_training_video_SARSA_agent.mp4')  # Adjust filename as needed\n"
      ],
      "metadata": {
        "id": "nYtTBKYatPy8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "07d3a2d4-3909-4241-a1da-3c585b44375c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5e3263be-25e7-4ca6-a70f-246c4005a0c5\", \"complete_training_video_SARSA_agent.mp4\", 76090)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop with Video Capturing\n",
        "from google.colab import files\n",
        "files.download('complete_training_video.mp4')  # Adjust filename as needed\n"
      ],
      "metadata": {
        "id": "fBW84GYcYyv8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "5166797a-7deb-477e-a1b4-413aad15576c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4daca82c-d551-4941-abd8-d972e24de3b1\", \"complete_training_video.mp4\", 31461)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}